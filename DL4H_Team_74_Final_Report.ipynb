{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FgTKlm-o7LP9"
   },
   "source": [
    "# **CS 598 Deep Learning for Healthcare Final Project**\n",
    "\n",
    "# **Domain Knowledge Guided Deep Learning with Electronic Health Records**\n",
    "\n",
    "\n",
    "\n",
    "Team ID: 74\n",
    "\n",
    "Paper ID: 69\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Byunggeun BK Park (bpark14@illinois.edu)\n",
    "\n",
    "Spencer Arbour (sarbour2@illinois.edu)\n",
    "\n",
    "Yun Gao (yungao3@illinois.edu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQ0sNuMePBXx"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "Please find our public repository at: https://drive.google.com/drive/folders/1SOuU9TfnHdI9R6mxhpTNvlaZ61zbgn5p?usp=sharing\n",
    "\n",
    "Public Github repository: https://github.com/BK1147/CS598_DLH_Final_Project.git\n",
    "\n",
    "Youtube or GDrive: https://drive.google.com/drive/folders/1SOuU9TfnHdI9R6mxhpTNvlaZ61zbgn5p?usp=sharing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "In the realm of healthcare, the utilization of Electronic Health Records (EHRs) for predictive analytics stands as a beacon of opportunity for enhancing patient care and resource allocation. However, the complexity inherent in EHR data, characterized by its high dimensionality, sparsity, and irregularity, poses formidable challenges to accurate prediction of clinical outcomes. Addressing these challenges is paramount for unlocking the full potential of EHRs in revolutionizing healthcare practices.\n",
    "\n",
    "This paper presents a pioneering solution to the intricate problem of clinical risk prediction using EHRs: the Domain Knowledge Guided Recurrent Neural Networks (DG-RNN). By seamlessly integrating rich medical knowledge into the predictive modeling process, DG-RNN transcends the limitations of conventional approaches, offering unprecedented accuracy, interpretability, and adaptability in clinical risk assessment.\n",
    "\n",
    "The cornerstone of DG-RNN lies in its innovative architecture, which harnesses the power of deep learning alongside domain-specific medical insights. Through a Graph-Based Attention Mechanism, the model dynamically incorporates complex relationships between medical events, treatments, and outcomes, enriching the predictive process with invaluable contextual information. Furthermore, a Global Max-Pooling Layer enhances interpretability by spotlighting the most influential medical events contributing to each prediction, thereby bridging the gap between data-driven predictions and clinical intuition.\n",
    "\n",
    "Key to the efficacy of DG-RNN is its adept handling of the idiosyncrasies of EHR data. By encoding temporal irregularities and leveraging advanced attention mechanisms, the model navigates the sparsity and irregularity of patient records with finesse, ensuring robust performance across diverse datasets and prediction tasks.\n",
    "\n",
    "Through rigorous evaluation on real-world EHR datasets, particularly focusing on heart failure risk prediction, DG-RNN showcases its superiority over traditional methods and contemporary deep learning approaches. Not only does it excel in accuracy, but it also stands out for its interpretability, aligning seamlessly with clinical insights and facilitating informed decision-making by healthcare practitioners.\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uygL9tTPSVHB"
   },
   "source": [
    "# Scope of Reproducibility\n",
    "\n",
    "The original paper introduces the Domain Knowledge Guided Recurrent Neural Networks (DG-RNN), a model that incorporates complex medical knowledge directly into the predictive modeling process using a recurrent neural network architecture. This model is equipped with a graph-based attention mechanism and a global max-pooling layer, designed to enhance predictive accuracy and interpretability for clinical outcomes. The study investigates four variations of the RNN model:\n",
    "\n",
    "1. RNN without additional layers\n",
    "2. RNN with reversed input layer\n",
    "3. RNN with global max-pooling\n",
    "4. RNN with global max-pooling + reversed input layer\n",
    "\n",
    "These models are evaluated against traditional machine learning methods such as Random Forest, Logistic Regression, and Support Vector Machine, as well as advanced deep learning models including GRU, LSTM, and RETAIN. Additionally, for the ablation study, we include a naive bi-directional RNN model with an additional reversed input layer to compare with other models.\n",
    "\n",
    "Due to the incomplete availability of the original implementation files and resources, we plan to recreate the high-level concepts and methodologies presented in the original paper. Our experimental setup will use the MIMIC-IV dataset to validate the effectiveness and reproducibility of the proposed methods.\n",
    "\n",
    "#### Hypotheses to be Tested\n",
    "\n",
    "- **Hypothesis 1**: The basic RNN model will outperform traditional machine learning methods (Random Forest, Logistic Regression, Support Vector Machine) in predicting patient risk. This is expected due to the RNN's ability to effectively capture temporal dependencies and sequential patterns in EHR data, which are critical for accurate clinical risk prediction.\n",
    "\n",
    "- **Hypothesis 2**: An RNN model enhanced with reversed input layer and a global max-pooling layer will exhibit superior performance compared to a basic RNN configuration. The reversed input layer is anticipated to improve the model’s ability to dynamically incorporate relevant medical knowledge, while the global max-pooling layer should help in capturing the most salient features from the input sequences, thus enhancing predictive accuracy and model generalization.\n",
    "\n",
    "By testing these hypotheses, we aim to assess the reproducibility of the original paper's claims and explore the practical benefits of advanced RNN architectures in clinical risk prediction using MIMIC-IV data. Through this process, we also plan to identify any potential challenges and limitations in replicating the study’s results, which will contribute valuable insights for future research in the field of healthcare analytics.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWAHJ_1CdtaA"
   },
   "source": [
    "# Methodology\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P61bNweuMbw8"
   },
   "source": [
    "## Environment\n",
    "\n",
    "Python version\n",
    "*  Python 3.11\n",
    "    \n",
    "Dependencies/packages needed\n",
    "*  Refer to requirements.txt file\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NbPHUTMbkD3"
   },
   "source": [
    "##  Data\n",
    "\n",
    "### Data download instruction\n",
    "*  An encrypted version of the electronic health records (EHRs) used for running our model have been include `enc_hfs_dataset_pkl`.\n",
    "*  A secret key can be found in <a href=\"https://drive.google.com/drive/folders/1GuJjVOCeXADcaQ6eqSlMZsx9IGR8UFxn?usp=share_link\">this</a> privately shared Google Drive folder. Save this file to the root directory for this project as `secret.key`.\n",
    "*  Alternatively, create a text file using Vim (or similar) to copy/paste the key provided, saving the file as `secret.key` in the root directory.\n",
    "\n",
    "\n",
    "### Original Data Description:\n",
    "The MIMIC IV dataset (version 2.2) originates from the comprehensive electronic health records (EHRs) at PhysioNet and includes a wide range of patient data collected for health research purposes. This dataset focuses specifically on patient information from the 'hosp' table, selectively filtered to include only ICD-9 diagnostic codes.\n",
    "\n",
    "#### Data Source and Version:\n",
    "- **Source**: PhysioNet\n",
    "- **Dataset Version**: MIMIC IV 2.2\n",
    "\n",
    "#### Data Selection and Preprocessing:\n",
    "- **Filtering Criteria**:\n",
    "  - Only entries with ICD-9 codes were retained to focus on diagnosable medical conditions.\n",
    "- **Preprocessing Details**:\n",
    "  - For comprehensive preprocessing steps including data cleaning and selection criteria, refer to the `Data_Preprocess.ipynb` notebook.\n",
    "\n",
    "#### Purpose of the Dataset:\n",
    "The dataset is primarily used for analyzing patient health trends and outcomes based on historical EHR data, with a specific emphasis on diagnosable conditions recorded through ICD-9 codes.\n",
    "\n",
    "#### Data Access and Usage:\n",
    "Researchers interested in detailed preprocessing steps, data filtering criteria, or specific analyses performed on this dataset should refer to the `Data_Preprocess.ipynb` notebook. This ensures a thorough understanding of the methods applied to the original data and supports reproducibility and transparency in health data research.\n",
    "\n",
    "---\n",
    "\n",
    "### After Filter Description:\n",
    "The dataset now contains patient visit records along with heart failure diagnosis information. Each patient is represented by a sequence of visits, where each visit includes relevant medical data and diagnostic information. The dataset aims to capture patterns and trends in patient visits leading up to the diagnosis of heart failure.\n",
    "\n",
    "#### Data Fields:\n",
    "1. **Visit Sequences (`seqs`)**:\n",
    "   - A list of lists representing the sequences of patient visits.\n",
    "   - Each outer list corresponds to a patient.\n",
    "   - Each inner list represents the visits for a particular patient, encoded using ICD9 codes.\n",
    "   \n",
    "2. **Heart Failure Diagnosis (`hfs`)**:\n",
    "   - A list of binary labels indicating heart failure diagnosis for each patient.\n",
    "   - Each label corresponds to a patient in the dataset.\n",
    "   - Value 1 indicates that heart failure was diagnosed at some point in the patient's medical history.\n",
    "   - Value 0 indicates no heart failure diagnosis.\n",
    "\n",
    "#### Data Structure:\n",
    "- **Visit Sequences**:\n",
    "  - Each patient's visit sequence may vary in length, depending on their medical history.\n",
    "  - The sequence may contain a variable number of visits, ranging from zero to multiple visits per patient.\n",
    "  - Visits are encoded using ICD9 codes, providing detailed medical information, including diagnosis codes and procedures.\n",
    "\n",
    "- **Heart Failure Diagnosis**:\n",
    "  - The heart failure diagnosis label is binary, indicating whether heart failure was diagnosed for each patient.\n",
    "  - A value of 1 signifies that heart failure was diagnosed for the corresponding patient, while a value of 0 indicates no heart failure diagnosis.\n",
    "\n",
    "#### Visualizations:\n",
    "- **Distribution of Diagnosis Counts per Visit**:\n",
    "  - A histogram showing the number of diagnoses recorded per visit, highlighting the complexity of medical conditions managed during each patient encounter.\n",
    "\n",
    "- **Frequency of Heart Failure Cases**:\n",
    "  - A bar chart illustrating the proportion of patients diagnosed with heart failure versus those not diagnosed, facilitating a quick visual assessment of the prevalence within the dataset.\n",
    "\n",
    "- **Visit Frequency per Patient**:\n",
    "  - A plot displaying the number of visits per patient, which helps in understanding patient engagement and utilization of healthcare resources over time.\n",
    "\n",
    "#### Data Analysis and Insights:\n",
    "- These visualizations enable a deeper understanding of the data, particularly in terms of the frequency and distribution of heart failure diagnoses and the overall visit patterns. They assist in identifying potential trends and areas for further research or intervention.\n",
    "---\n",
    "\n",
    "This combined description outlines the dataset’s origin, the modifications made, and the enhanced possibilities for analysis and application post-processing. If you need further adjustments or additional details, let me know!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GAAIqkV9Mvja"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "# set seed\n",
    "seed = 24\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "# ensure data path exists in directory\n",
    "DATA_PATH = 'data/'\n",
    "DATA_PATH_PICKLE = 'data/'\n",
    "os.makedirs(os.path.dirname(DATA_PATH), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleans up file structure from previous runs (if any)\n",
    "dir = DATA_PATH\n",
    "\n",
    "for file in os.listdir(dir):\n",
    "    file_path = os.path.join(dir, file)\n",
    "    os.remove(file_path)\n",
    "\n",
    "if os.path.isfile('enc_diagnoses'):\n",
    "    os.remove('enc_diagnoses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unencrypt `enc_hfs_dataset_pkl` and store in `data` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryptography.fernet import Fernet\n",
    "\n",
    "with open('secret.key', 'rb') as mykey:\n",
    "    key = mykey.read()\n",
    "\n",
    "f = Fernet(key)\n",
    "\n",
    "with open('enc_hfs_dataset_pkl', 'rb') as encrypted_file:\n",
    "    encrypted = encrypted_file.read()\n",
    "\n",
    "decrypted = f.decrypt(encrypted)\n",
    "\n",
    "with open(os.path.join(DATA_PATH,'hfs_dataset_pkl.zip'), 'wb') as decrypted_file:\n",
    "    decrypted_file.write(decrypted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip pickle files and store in /data directory\n",
    "import shutil\n",
    "import pathlib\n",
    "\n",
    "shutil.unpack_archive(os.path.join(DATA_PATH,'hfs_dataset_pkl.zip'), os.path.join(DATA_PATH,'hfs_pickle_files/'), format='zip')\n",
    "\n",
    "dir = os.path.join(DATA_PATH, 'hfs_pickle_files/')\n",
    "\n",
    "for file in os.listdir(dir):\n",
    "    file_path = os.path.join(dir, file)\n",
    "    shutil.move(file_path, DATA_PATH)\n",
    "\n",
    "zip_file_path = pathlib.Path(os.path.join(DATA_PATH, 'hfs_dataset_pkl.zip'))\n",
    "zip_file_path.unlink()\n",
    "\n",
    "extracted_dir_path = pathlib.Path(os.path.join(DATA_PATH, 'hfs_pickle_files'))\n",
    "extracted_dir_path.rmdir()\n",
    "# pathlib.Path.unlink(os.path.join(DATA_PATH, 'hfs_dataset_pkl.zip'))\n",
    "# pathlib.Path.rmdir(os.path.join(DATA_PATH, 'hfs_pickle_files'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "iaP-KPzpDnYE"
   },
   "outputs": [],
   "source": [
    "# comment for the each data\n",
    "pids = pickle.load(open(os.path.join(DATA_PATH_PICKLE,'pids.pickle'), 'rb'))\n",
    "vids = pickle.load(open(os.path.join(DATA_PATH_PICKLE,'vids.pickle'), 'rb'))\n",
    "hfs = pickle.load(open(os.path.join(DATA_PATH_PICKLE,'hfs.pickle'), 'rb'))\n",
    "seqs = pickle.load(open(os.path.join(DATA_PATH_PICKLE,'seqs.pickle'), 'rb'))\n",
    "types = pickle.load(open(os.path.join(DATA_PATH_PICKLE,'types.pickle'), 'rb'))\n",
    "rtypes = pickle.load(open(os.path.join(DATA_PATH_PICKLE,'rtypes.pickle'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tCPNgzPahm6Q",
    "outputId": "e3956ade-013e-42e4-a53e-544619939d1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36975"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "DATA_PATH = \"./data\"\n",
    "pids = pickle.load(open(os.path.join(DATA_PATH,'pids.pickle'), 'rb'))\n",
    "vids = pickle.load(open(os.path.join(DATA_PATH,'vids.pickle'), 'rb'))\n",
    "hfs = pickle.load(open(os.path.join(DATA_PATH,'hfs.pickle'), 'rb'))\n",
    "seqs = pickle.load(open(os.path.join(DATA_PATH,'seqs.pickle'), 'rb'))\n",
    "types = pickle.load(open(os.path.join(DATA_PATH,'types.pickle'), 'rb'))\n",
    "rtypes = pickle.load(open(os.path.join(DATA_PATH,'rtypes.pickle'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: 10001860\n",
      "Heart Failure: 0\n",
      "# of visits: 1\n",
      "\t0-th visit id: 23334588\n",
      "\t0-th visit diagnosis labels: [2743, 925, 4756, 1095, 2244, 2304, 1057, 1389, 1204, 2944, 4960, 1815, 4936, 4855, 4872, 2299, 5012]\n",
      "\t0-th visit diagnosis codes: ['4829', '25000', '78060', '2761', '4019', '41401', '2724', '30000', '2859', '53081', '79311', '34982', '7904', '78701', '78791', '412', '79902']\n"
     ]
    }
   ],
   "source": [
    "print(\"Patient ID:\", pids[5])\n",
    "print(\"Heart Failure:\", hfs[5])\n",
    "print(\"# of visits:\", len(vids[5]))\n",
    "for visit in range(len(vids[5])):\n",
    "    print(f\"\\t{visit}-th visit id:\", vids[3][visit])\n",
    "    print(f\"\\t{visit}-th visit diagnosis labels:\", seqs[3][visit])\n",
    "    print(f\"\\t{visit}-th visit diagnosis codes:\", [rtypes[label] for label in seqs[3][visit]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([[2406, 2751, 2846, 412, 2298, 6078, 2397, 2789, 1384, 2386, 2255, 3277, 2304, 925, 7084, 1979, 910, 6905], [2406, 2846, 1801, 2387, 17, 412, 1096, 1094, 3273, 2397, 2386, 2491, 2269, 2255, 2976, 7159, 2395, 2789, 1534, 1105, 4860, 4876, 7230, 927, 7084, 2304, 1979, 886, 7276], [2406, 2751, 3270, 2298, 2397, 2304, 2386, 2255, 3277, 3279, 925, 2789, 6843, 4840, 4860, 4980]], 1)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, seqs, hfs):\n",
    "        \n",
    "        self.x = seqs  # Store diagnosis sequences\n",
    "        self.y = hfs   # Store heart failure outcomes\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)  # Number of patients\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "        \n",
    "\n",
    "dataset = CustomDataset(seqs, hfs)\n",
    "\n",
    "print(dataset[1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Diagnosis Counts per Visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "diagnoses_per_visit = [len(visit) for patient in dataset.x for visit in patient]\n",
    "plt.hist(diagnoses_per_visit, bins=range(1, max(diagnoses_per_visit)+2), align='left')\n",
    "plt.title('Distribution of Diagnosis Counts per Visit')\n",
    "plt.xlabel('Number of Diagnoses')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency of Heart Failure Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "hf_labels = [hf for _, hf in dataset]\n",
    "\n",
    "num_heart_failure = sum(hf_labels)\n",
    "num_no_heart_failure = len(hf_labels) - num_heart_failure\n",
    "\n",
    "labels = ['No Heart Failure', 'Heart Failure']\n",
    "sizes = [num_no_heart_failure, num_heart_failure]\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%')\n",
    "plt.title('Proportion of Heart Failure Cases')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visit Frequency per Patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visit_counts = Counter(len(patient) for patient in dataset.x)\n",
    "plt.bar(visit_counts.keys(), visit_counts.values())\n",
    "plt.title('Number of Visits per Patient')\n",
    "plt.xlabel('Number of Visits')\n",
    "plt.ylabel('Number of Patients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNSdhPkuaK9K"
   },
   "source": [
    "### Pre-processing: Filter 'patient_df' and 'diagnoses_df' into list data used for RNN\n",
    "\n",
    "where\n",
    "* pids: contains the patient ids\n",
    "* vids: contains a list of visit ids for each patient\n",
    "* hfs: contains the heart failure label (0: normal, 1: heart failure) for each patient\n",
    "* seqs: contains a list of visit (in ICD9 codes) for each patient\n",
    "* types: contains the map from ICD9 codes to ICD-9 labels\n",
    "* rtypes: contains the map from ICD9 labels to ICD9 codes\n",
    "\n",
    "Read in `d_icd_diagnoses.csv` and `diagnoses.csv` as Pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('enc_d_icd_diagnoses', 'rb') as encrypted_file:\n",
    "    encrypted = encrypted_file.read()\n",
    "\n",
    "decrypted = f.decrypt(encrypted)\n",
    "\n",
    "with open(os.path.join(DATA_PATH,'d_icd_diagnoses.csv'), 'wb') as decrypted_file:\n",
    "    decrypted_file.write(decrypted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wZNf6Sp2Yl-D",
    "outputId": "a8b8b792-6be1-4fcf-b7f0-c33a5b495fe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  icd_code  icd_version                             long_title\n",
      "0     0010            9         Cholera due to vibrio cholerae\n",
      "1     0011            9  Cholera due to vibrio cholerae el tor\n",
      "2     0019            9                   Cholera, unspecified\n",
      "3     0020            9                          Typhoid fever\n",
      "4     0021            9                    Paratyphoid fever A\n"
     ]
    }
   ],
   "source": [
    "d_icd_diagnoses_df = pd.read_csv(DATA_PATH + '/d_icd_diagnoses.csv', sep=',', header='infer')\n",
    "print(d_icd_diagnoses_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1sZIXoSLOnC0W6D5DxQFXmsJozBO_gcGX\n",
      "From (redirected): https://drive.google.com/uc?id=1sZIXoSLOnC0W6D5DxQFXmsJozBO_gcGX&confirm=t&uuid=e0cc42a4-1d25-472a-9500-995eb80f9597\n",
      "To: /Users/spenny/CS598_Final_Proj/CS598_DLH_Final_Project/enc_diagnoses\n",
      "100%|██████████| 180M/180M [00:05<00:00, 33.1MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'enc_diagnoses'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "url = \"https://drive.google.com/file/d/1sZIXoSLOnC0W6D5DxQFXmsJozBO_gcGX/view?usp=share_link\"\n",
    "output = 'enc_diagnoses'\n",
    "\n",
    "gdown.download(url=url, output=output, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('enc_diagnoses', 'rb') as encrypted_file:\n",
    "    encrypted = encrypted_file.read()\n",
    "\n",
    "decrypted = f.decrypt(encrypted)\n",
    "\n",
    "with open(os.path.join(DATA_PATH,'diagnoses_icd.csv'), 'wb') as decrypted_file:\n",
    "    decrypted_file.write(decrypted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GVevf6drZWhN",
    "outputId": "451bee96-2078-4b66-bb36-0206eab52b85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject_id   hadm_id  seq_num icd_code  icd_version\n",
      "0    10000032  22595853        1     5723            9\n",
      "1    10000032  22595853        2    78959            9\n",
      "2    10000032  22595853        3     5715            9\n",
      "3    10000032  22595853        4    07070            9\n",
      "4    10000032  22595853        5      496            9\n"
     ]
    }
   ],
   "source": [
    "diagnoses_df = pd.read_csv(DATA_PATH + '/diagnoses_icd.csv', sep=',', header='infer')\n",
    "print(diagnoses_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2YXZRv2h-J9"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "The MIMIC-IV dataset is a large and comprehensive collection of medical records, containing over 120,000 unique patient identifiers ('pid'). While this extensive dataset provides a wealth of information, training machine learning models on such a vast dataset can lead to overtraining and overfitting issues. Overfitting occurs when a model learns the training data too well, including its noise and outliers, thereby reducing its ability to generalize to new, unseen data.\n",
    "\n",
    "To mitigate these challenges and improve the model's performance, we have decided to train our models on a smaller, carefully selected subset of the MIMIC-IV dataset. By focusing on a more manageable dataset, we aim to create models that are more robust, generalize better to new data, and ultimately yield more reliable predictions in clinical settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "w10A2Aqi2HPh"
   },
   "outputs": [],
   "source": [
    "total_length = len(pids)\n",
    "random_indices = random.sample(range(total_length), 1000)\n",
    "\n",
    "# Select the 2000 elements using the random indices\n",
    "pids = [pids[i] for i in random_indices]\n",
    "vids = [vids[i] for i in random_indices]\n",
    "hfs = [hfs[i] for i in random_indices]\n",
    "seqs = [seqs[i] for i in random_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRk7-KR2fW8I"
   },
   "source": [
    "Pre-Processing for Machine Learning model: Random Forest (RF), Logistic Regression(LR), Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "rOHNOh8a3xOQ"
   },
   "outputs": [],
   "source": [
    "d_icd_diagnoses_df = pd.read_csv(DATA_PATH + '/d_icd_diagnoses.csv', sep=',', header='infer')\n",
    "diagnoses_df = pd.read_csv(DATA_PATH + '/diagnoses_icd.csv', sep=',', header='infer')\n",
    "\n",
    "merged_df = pd.merge(diagnoses_df,d_icd_diagnoses_df, on=['icd_code', 'icd_version'], how='left')\n",
    "merged_df['hfs'] = merged_df['long_title'].str.contains(\"heart failure\").astype(int)\n",
    "merged_df = merged_df[merged_df['icd_version'] == 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "QEB7CHUUg1fk"
   },
   "outputs": [],
   "source": [
    "grouped_df = merged_df.groupby('subject_id').agg({\n",
    "    'seq_num': 'sum',\n",
    "    'hfs': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "grouped_df = grouped_df[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3muyDPFPbozY"
   },
   "source": [
    "##  Model\n",
    "\n",
    "Model architecture\n",
    "\n",
    "---\n",
    "\n",
    "**RNN without additional layers**\n",
    "\n",
    "Layers | Configuration | Activation Function | Output Dimension (batch, feature)\n",
    "--- | --- | --- | ---\n",
    "Embedding | num_embeddings=num_codes, embedding_dim=128 | - | (batch_size, seq_len, embedding_dim)\n",
    "GRU (RNN) | input_size=128, hidden_size=hidden_size | - | (batch_size, seq_len, hidden_size)\n",
    "Linear (fully connected) | input_size=hidden_size , output_size=1 | - | (batch_size, 1)\n",
    "Sigmoid | - | - | (batch_size, 1)\n",
    "\n",
    "**RNN with reversed input layer**\n",
    "\n",
    "Layers | Configuration | Activation Function | Output Dimension (batch, feature)\n",
    "--- | --- | --- | ---\n",
    "Embedding | num_embeddings=num_codes, embedding_dim=128 | - | (batch_size, seq_len, embedding_dim)\n",
    "GRU (RNN) | input_size=128, hidden_size=hidden_size | - | (batch_size, seq_len, hidden_size)\n",
    "GRU (Reverse RNN) | input_size=128, hidden_size=hidden_size | - | (batch_size, seq_len, hidden_size)\n",
    "Linear (fully connected) | input_size=hidden_size * 2, output_size=1 | - | (batch_size, 1)\n",
    "Sigmoid | - | - | (batch_size, 1)\n",
    "\n",
    "**RNN with global max-pooling layer**\n",
    "\n",
    "Layers | Configuration | Activation Function | Output Dimension (batch, feature)\n",
    "--- | --- | --- | ---\n",
    "Embedding | num_embeddings=num_codes, embedding_dim=128 | - | (batch_size, seq_len, embedding_dim)\n",
    "GRU (RNN) | input_size=128, hidden_size=hidden_size | - | (batch_size, seq_len, hidden_size)\n",
    "AdaptiveMaxPool1d | output_size=hidden_size | - | (batch_size, hidden_size)\n",
    "Linear (fully connected) | input_size=hidden_size, output_size=1 | - | (batch_size, 1)\n",
    "Sigmoid | - | - | (batch_size, 1)\n",
    "\n",
    "**RNN with global max-pooling layer + reversed input layer**\n",
    "\n",
    "Layers | Configuration | Activation Function | Output Dimension (batch, feature)\n",
    "--- | --- | --- | ---\n",
    "Embedding | num_embeddings=num_codes, embedding_dim=128 | - | (batch_size, seq_len, embedding_dim)\n",
    "GRU (RNN) | input_size=128, hidden_size=hidden_size | - | (batch_size, seq_len, hidden_size)\n",
    "GRU (Reverse RNN) | input_size=128, hidden_size=hidden_size | - | (batch_size, seq_len, hidden_size)\n",
    "AdaptiveMaxPool1d | output_size=hidden_size | - | (batch_size, hidden_size)\n",
    "Linear (fully connected) | input_size=hidden_size * 2, output_size=1 | - | (batch_size, 1)\n",
    "Sigmoid | - | - | (batch_size, 1)\n",
    "\n",
    "\n",
    "Training objectives:\n",
    "*   Loss Function: Binary Cross-Entropy Loss (assuming the model is for binary classification since the output is passed through a sigmoid activation).\n",
    "*   Optimizer: Adam optimizer with a learning rate of 1e-3.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Disclamer\n",
    "\n",
    "Disclaimer: We utilized the basic RNN structure code from Homework 3 for the RNN model. Using this basic structure as a foundation, we will combine it with a naive bi-directional mechanism and a global max-pooling layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "iJ2fvsicKFyW"
   },
   "outputs": [],
   "source": [
    "# Custom dataset\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, seqs, hfs):\n",
    "    self.seqs = seqs\n",
    "    self.hfs = hfs\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.seqs)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.seqs[index], self.hfs[index]\n",
    "\n",
    "dataset = CustomDataset(seqs, hfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "_bx4P_G9KFkR"
   },
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    sequences, labels = zip(*data)\n",
    "    y = torch.tensor(labels, dtype=torch.float)\n",
    "\n",
    "    num_patients = len(sequences)\n",
    "    num_visits = [len(patient) for patient in sequences]\n",
    "    num_codes = [len(visit) for patient in sequences for visit in patient]\n",
    "\n",
    "    max_num_visits = max(num_visits)\n",
    "    max_num_codes = max(num_codes)\n",
    "\n",
    "    x = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.long)\n",
    "    rev_x = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.long)\n",
    "    masks = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.bool)\n",
    "    rev_masks = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.bool)\n",
    "    for i_patient, patient in enumerate(sequences):\n",
    "        for j_visit, visit in enumerate(patient):\n",
    "            padded_visit = torch.tensor(visit + [0] * (max_num_codes - len(visit)), dtype=torch.long)\n",
    "            x[i_patient, j_visit, :] = padded_visit\n",
    "            masks[i_patient, j_visit, :] = padded_visit != 0\n",
    "\n",
    "    for i_patient, patient in enumerate(sequences):\n",
    "        idx_all_real_visits = torch.sum(x[i_patient, :, :], dim=1) != 0\n",
    "        idx_padded_visits = torch.sum(x[i_patient, :, :], dim=1) == 0\n",
    "        reversed_real_visits = torch.flip(x[i_patient, idx_all_real_visits, :], dims=(0,))\n",
    "        rev_x[i_patient, :, :] = torch.cat((reversed_real_visits, x[i_patient, idx_padded_visits, :]), dim=0)\n",
    "        rev_masks[i_patient, :, :] = rev_x[i_patient, :, :] != 0\n",
    "\n",
    "    return x, masks, rev_x, rev_masks, y\n",
    "\n",
    "def load_data(train_dataset, val_dataset, collate_fn):\n",
    "    batch_size = 32\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def sum_embeddings_with_mask(x, masks):\n",
    "\n",
    "    masked_embeddings = x * masks.unsqueeze(-1)\n",
    "    sum_embeddings = masked_embeddings.sum(dim=2)\n",
    "\n",
    "    return sum_embeddings\n",
    "\n",
    "def get_last_visit(hidden_states, masks):\n",
    "\n",
    "    true_visit_length = torch.sum(masks, dim=1)\n",
    "    idx_last_visit = true_visit_length[:,0] - 1\n",
    "    last_hidden_state = hidden_states[torch.arange(hidden_states.size(0)), idx_last_visit, :]\n",
    "\n",
    "    return last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t2lFISxgQ8Uj",
    "outputId": "5104a60f-1b7f-4008-a9ae-f75bfba8b1da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 800\n",
      "Length of train with HF: 298\n",
      "Length of train with survive patients: 502\n",
      "Length of val dataset: 200\n",
      "Length of val with HF: 77\n",
      "Length of val with survive patients: 723\n"
     ]
    }
   ],
   "source": [
    "split = int(len(dataset)*0.8)\n",
    "\n",
    "lengths = [split, len(dataset) - split]\n",
    "train_dataset, val_dataset = random_split(dataset, lengths)\n",
    "\n",
    "train_loader, val_loader = load_data(train_dataset, val_dataset, collate_fn)\n",
    "print(\"Length of train dataset:\", len(train_dataset))\n",
    "print(\"Length of train with HF:\", np.sum([element[-1] for element in train_dataset]))\n",
    "print(\"Length of train with survive patients:\", (len(train_dataset) - np.sum([element[-1] for element in train_dataset])))\n",
    "print(\"Length of val dataset:\", len(val_dataset))\n",
    "print(\"Length of val with HF:\", np.sum([element[-1] for element in val_dataset]))\n",
    "print(\"Length of val with survive patients:\", (len(train_dataset) - np.sum([element[-1] for element in val_dataset])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN without additional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "VtHFMPKdX9EP"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_codes, learning_rate = 0.01, hidden_size = 128, dropout = 0):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_codes, embedding_dim=128)\n",
    "\n",
    "        self.rnn = nn.GRU(input_size=128, hidden_size=hidden_size, batch_first=True, dropout=0)\n",
    "\n",
    "        self.fc = nn.Linear(in_features=hidden_size, out_features=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, masks, rev_x, rev_masks):\n",
    "\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x = sum_embeddings_with_mask(x, masks)\n",
    "        output, _ = self.rnn(x)\n",
    "        true_h_n = get_last_visit(output, masks)\n",
    "\n",
    "        logits = self.fc(true_h_n)\n",
    "        probs = self.sigmoid(logits)\n",
    "\n",
    "        return probs.view(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN with reversed input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "7bVA2ugC3_bk"
   },
   "outputs": [],
   "source": [
    "class RNN_Rev(nn.Module):\n",
    "\n",
    "    def __init__(self, num_codes, learning_rate = 0.01, hidden_size = 128, dropout = 0):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_codes, embedding_dim=128)\n",
    "\n",
    "        self.rnn = nn.GRU(input_size=128, hidden_size=hidden_size, batch_first=True, dropout=0)\n",
    "\n",
    "        self.rev_rnn = nn.GRU(input_size=128, hidden_size=hidden_size, batch_first=True, dropout=0)\n",
    "\n",
    "        self.fc = nn.Linear(in_features=hidden_size * 2, out_features=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, masks, rev_x, rev_masks):\n",
    "\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x = sum_embeddings_with_mask(x, masks)\n",
    "        output, _ = self.rnn(x)\n",
    "        true_h_n = get_last_visit(output, masks)\n",
    "\n",
    "        true_h_n_rev = None\n",
    "\n",
    "        rev_x = self.embedding(rev_x)\n",
    "        rev_x = sum_embeddings_with_mask(rev_x, masks)\n",
    "\n",
    "        rev_output, _ = self.rnn(rev_x)\n",
    "        true_h_n_rev = get_last_visit(rev_output, masks)\n",
    "\n",
    "        logits = self.fc(torch.cat([true_h_n, true_h_n_rev], 1))\n",
    "        probs = self.sigmoid(logits)\n",
    "\n",
    "        return probs.view(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN with global max-pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "H7QYN5CaQ8BS"
   },
   "outputs": [],
   "source": [
    "class RNN_Pool(nn.Module):\n",
    "\n",
    "    def __init__(self, num_codes, learning_rate = 0.01, hidden_size = 128, dropout = 0):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_codes, embedding_dim=128)\n",
    "\n",
    "        self.rnn = nn.GRU(input_size=128, hidden_size=hidden_size, batch_first=True, dropout=0)\n",
    "\n",
    "        self.maxpooling = nn.AdaptiveMaxPool1d(hidden_size)  # Add AdaptiveMaxPool1d layer\n",
    "\n",
    "        self.fc = nn.Linear(in_features=hidden_size, out_features=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, masks, rev_x, rev_masks):\n",
    "        # x, masks, y, adj_matrices\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x = sum_embeddings_with_mask(x, masks)\n",
    "        output, _ = self.rnn(x)\n",
    "        true_h_n = get_last_visit(output, masks)\n",
    "\n",
    "        x_max = self.maxpooling(true_h_n.unsqueeze(2).permute(0, 2, 1)).squeeze(2)\n",
    "\n",
    "        logits = self.fc(x_max) # for maxpooling layer\n",
    "        probs = self.sigmoid(logits)\n",
    "\n",
    "        return probs.view(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN with global max-pooling + reversed input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "JFfhNkLUKyYO"
   },
   "outputs": [],
   "source": [
    "class RNN_Rev_Pool(nn.Module):\n",
    "\n",
    "    def __init__(self, num_codes, learning_rate = 0.01, hidden_size = 128, dropout = 0):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_codes, embedding_dim=128)\n",
    "\n",
    "        self.rnn = nn.GRU(input_size=128, hidden_size=hidden_size, batch_first=True, dropout=0)\n",
    "        self.rev_rnn = nn.GRU(input_size=128, hidden_size=hidden_size, batch_first=True, dropout=0)\n",
    "\n",
    "        self.maxpooling = nn.AdaptiveMaxPool1d(hidden_size)  # Add AdaptiveMaxPool1d layer\n",
    "\n",
    "        self.fc = nn.Linear(in_features=hidden_size * 2, out_features=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x, masks, rev_x, rev_masks):\n",
    "\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x = sum_embeddings_with_mask(x, masks)\n",
    "        output, _ = self.rnn(x)\n",
    "        true_h_n = get_last_visit(output, masks)\n",
    "\n",
    "        true_h_n_rev = None\n",
    "        rev_x = self.embedding(rev_x)\n",
    "        rev_x = sum_embeddings_with_mask(rev_x, masks)\n",
    "\n",
    "        rev_output, _ = self.rnn(rev_x)\n",
    "        true_h_n_rev = get_last_visit(rev_output, masks)\n",
    "\n",
    "        true_h_n_max = self.maxpooling(true_h_n.unsqueeze(2).permute(0, 2, 1)).squeeze(2)\n",
    "        true_h_n_rev_max = self.maxpooling(true_h_n_rev.unsqueeze(2).permute(0, 2, 1)).squeeze(2)\n",
    "\n",
    "        logits = self.fc(torch.cat([true_h_n_max, true_h_n_rev_max], 2)) \n",
    "        probs = self.sigmoid(logits)\n",
    "\n",
    "        return probs.view(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "fXmSiIEcVn3o"
   },
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jA6J5w0yb49P",
    "outputId": "4e8e95f2-ed42-4b59-9032-30563df9c78c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3yysELMYXip"
   },
   "source": [
    "## Training\n",
    "\n",
    "Hyperparams\n",
    "\n",
    "* RNN without additional layers\n",
    "    * Best hyperparameters: {'dropout': 0.1, 'hidden_size': 256, 'learning_rate': 0.01}\n",
    "* RNN with reversed input layer\n",
    "    * Best hyperparameters: {'dropout': 0.1, 'hidden_size': 64, 'learning_rate': 0.01}\n",
    "* RNN with global max-pooling\n",
    "    * Best hyperparameters: {'dropout': 0.1, 'hidden_size': 128, 'learning_rate': 0.01}\n",
    "* RNN with global max-pooling + reversed input layer\n",
    "    * Best hyperparameters: {'dropout': 0.0, 'hidden_size': 128, 'learning_rate': 0.01}\n",
    "\n",
    "\n",
    "Computational requirements\n",
    "\n",
    "*   This code ran success fully on a system with the following specifications:\n",
    "    * Processor: 2.6 GHz Quad-Core intel Core i7\n",
    "    * Memory: 16 GH 2133 MHz LPDDR3\n",
    "    * Gradeon Pro 450 2GB Intel HD Graphics 530 1536MB\n",
    "\n",
    "Execution time \n",
    "\n",
    "* RNN without additional layers: 1 - 2 mins\n",
    "* RNN with reversed input layer: 1 - 2 mins\n",
    "* RNN with global max-pooling: 2 - 3 mins\n",
    "* RNN with global max-pooling + reversed input layer: 2 - 3 mins\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "oa9PzOgIVnvl"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "def eval_model(model, val_loader):\n",
    "    model.to(device).eval()\n",
    "    y_pred = torch.LongTensor()\n",
    "    y_score = torch.Tensor()\n",
    "    y_true = torch.LongTensor()\n",
    "    model.eval()\n",
    "    for x, masks, rev_x, rev_masks, y in val_loader:\n",
    "        #x, masks, rev_x, rev_masks, y = x.to(device), masks.to(device), rev_x.to(device), rev_masks.to(device), y.to(device)\n",
    "\n",
    "        y_hat = model(x, masks, rev_x, rev_masks)\n",
    "        y_score = torch.cat((y_score,  y_hat.detach().to('cpu')), dim=0)\n",
    "        y_hat = (y_hat > 0.5).int()\n",
    "\n",
    "        y_pred = torch.cat((y_pred,  y_hat.detach().to('cpu')), dim=0)\n",
    "        y_true = torch.cat((y_true, y.detach().to('cpu')), dim=0)\n",
    "\n",
    "    p, r, f, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "    roc_auc = roc_auc_score(y_true, y_score)\n",
    "\n",
    "    return p, r, f, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "hgrvWizb77Gf"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'hidden_size': [64, 128, 256],\n",
    "    'dropout': [0.0, 0.1]\n",
    "}\n",
    "\n",
    "def train_with_hyperparameter_tuning(model, train_loader, val_loader, n_epochs, param_grid):\n",
    "    best_roc_auc_score = 0\n",
    "    best_params = None\n",
    "\n",
    "    # Loop over hyperparameter combinations\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        print(\"Training with hyperparameters:\", params)\n",
    "\n",
    "        # Initialize the model with current hyperparameters\n",
    "        current_model = model(num_codes=len(types), **params).to(device)\n",
    "        optimizer = torch.optim.Adam(current_model.parameters(), lr=params['learning_rate'])\n",
    "        print(f\"current_model: {current_model}\")\n",
    "        # Training loop\n",
    "        for epoch in range(n_epochs):\n",
    "            current_model.train()\n",
    "            train_loss = 0\n",
    "            for x, masks, rev_x, rev_masks, y in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                y_hat = current_model(x, masks, rev_x, rev_masks)\n",
    "                y_hat = y_hat.view(y_hat.shape[0])\n",
    "                loss = criterion(y_hat, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "\n",
    "            train_loss = train_loss / len(train_loader)\n",
    "            print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        _, _, _, roc_auc = eval_model(current_model, val_loader)\n",
    "        print(\"Validation roc_auc with current hyperparameters:\", roc_auc)\n",
    "\n",
    "        # Check if this set of hyperparameters is the best so far\n",
    "        if roc_auc > best_roc_auc_score:\n",
    "            best_roc_auc_score = roc_auc\n",
    "            best_params = params\n",
    "\n",
    "    print(\"Best hyperparameters:\", best_params)\n",
    "    print(\"Best roc_auc score:\", best_roc_auc_score)\n",
    "\n",
    "    # Train the model with the best hyperparameters on the full training set\n",
    "    best_model = model(num_codes=len(types), **best_params).to(device)\n",
    "    optimizer = torch.optim.Adam(best_model.parameters(), lr=best_params['learning_rate'])\n",
    "    for epoch in range(n_epochs):\n",
    "        best_model.train()\n",
    "        train_loss = 0\n",
    "        for x, masks, rev_x, rev_masks, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = best_model(x, masks, rev_x, rev_masks)\n",
    "            y_hat = y_hat.view(y_hat.shape[0])\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ESKidmKYFtnJ",
    "outputId": "3bf48171-2354-4fc6-961f-713165fbbac7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 64, 'learning_rate': 0.001}\n",
      "current_model: RNN(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 64, batch_first=True)\n",
      "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.638951\n",
      "Epoch: 2 \t Training Loss: 0.472035\n",
      "Epoch: 3 \t Training Loss: 0.334809\n",
      "Epoch: 4 \t Training Loss: 0.224091\n",
      "Epoch: 5 \t Training Loss: 0.144595\n",
      "Validation roc_auc with current hyperparameters: 0.937493400908035\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 64, 'learning_rate': 0.01}\n",
      "current_model: RNN(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 64, batch_first=True)\n",
      "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.418942\n",
      "Epoch: 2 \t Training Loss: 0.077669\n",
      "Epoch: 3 \t Training Loss: 0.013355\n",
      "Epoch: 4 \t Training Loss: 0.003987\n",
      "Epoch: 5 \t Training Loss: 0.001999\n",
      "Validation roc_auc with current hyperparameters: 0.9826839826839826\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 64, 'learning_rate': 0.1}\n",
      "current_model: RNN(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 64, batch_first=True)\n",
      "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.410378\n",
      "Epoch: 2 \t Training Loss: 0.154365\n",
      "Epoch: 3 \t Training Loss: 0.096776\n",
      "Epoch: 4 \t Training Loss: 0.075727\n",
      "Epoch: 5 \t Training Loss: 0.051809\n",
      "Validation roc_auc with current hyperparameters: 0.9767711962833914\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 128, 'learning_rate': 0.001}\n",
      "current_model: RNN(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 128, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.573420\n",
      "Epoch: 2 \t Training Loss: 0.321743\n",
      "Epoch: 3 \t Training Loss: 0.172076\n",
      "Epoch: 4 \t Training Loss: 0.091791\n",
      "Epoch: 5 \t Training Loss: 0.054125\n",
      "Validation roc_auc with current hyperparameters: 0.9617780593390349\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 128, 'learning_rate': 0.01}\n",
      "current_model: RNN(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 128, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.411707\n",
      "Epoch: 2 \t Training Loss: 0.052889\n",
      "Epoch: 3 \t Training Loss: 0.005099\n",
      "Epoch: 4 \t Training Loss: 0.001488\n",
      "Epoch: 5 \t Training Loss: 0.000874\n",
      "Validation roc_auc with current hyperparameters: 0.9658958927251611\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 128, 'learning_rate': 0.1}\n",
      "current_model: RNN(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 128, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.532737\n",
      "Epoch: 2 \t Training Loss: 0.271145\n",
      "Epoch: 3 \t Training Loss: 0.132260\n",
      "Epoch: 4 \t Training Loss: 0.131942\n",
      "Epoch: 5 \t Training Loss: 0.135032\n",
      "Validation roc_auc with current hyperparameters: 0.9452011403230914\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 256, 'learning_rate': 0.001}\n",
      "current_model: RNN(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 256, batch_first=True)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.493528\n",
      "Epoch: 2 \t Training Loss: 0.201057\n",
      "Epoch: 3 \t Training Loss: 0.087300\n",
      "Epoch: 4 \t Training Loss: 0.044892\n",
      "Epoch: 5 \t Training Loss: 0.025100\n",
      "Validation roc_auc with current hyperparameters: 0.9625171576391088\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 256, 'learning_rate': 0.01}\n",
      "current_model: RNN(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 256, batch_first=True)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.358449\n",
      "Epoch: 2 \t Training Loss: 0.021501\n",
      "Epoch: 3 \t Training Loss: 0.003717\n",
      "Epoch: 4 \t Training Loss: 0.000801\n",
      "Epoch: 5 \t Training Loss: 0.000479\n",
      "Validation roc_auc with current hyperparameters: 0.9796220040122481\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 256, 'learning_rate': 0.1}\n",
      "current_model: RNN(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 256, batch_first=True)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.828900\n",
      "Epoch: 2 \t Training Loss: 0.220495\n",
      "Epoch: 3 \t Training Loss: 0.181238\n",
      "Epoch: 4 \t Training Loss: 0.090135\n",
      "Epoch: 5 \t Training Loss: 0.069241\n",
      "Validation roc_auc with current hyperparameters: 0.9630450849963045\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 64, 'learning_rate': 0.001}\n",
      "current_model: RNN(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 64, batch_first=True)\n",
      "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.593849\n",
      "Epoch: 2 \t Training Loss: 0.421636\n",
      "Epoch: 3 \t Training Loss: 0.290154\n",
      "Epoch: 4 \t Training Loss: 0.189002\n",
      "Epoch: 5 \t Training Loss: 0.119902\n",
      "Validation roc_auc with current hyperparameters: 0.953647978038222\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 64, 'learning_rate': 0.01}\n",
      "current_model: RNN(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 64, batch_first=True)\n",
      "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.361709\n",
      "Epoch: 2 \t Training Loss: 0.049918\n",
      "Epoch: 3 \t Training Loss: 0.009212\n",
      "Epoch: 4 \t Training Loss: 0.002843\n",
      "Epoch: 5 \t Training Loss: 0.001538\n",
      "Validation roc_auc with current hyperparameters: 0.9805722732552\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 64, 'learning_rate': 0.1}\n",
      "current_model: RNN(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 64, batch_first=True)\n",
      "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.418547\n",
      "Epoch: 2 \t Training Loss: 0.160591\n",
      "Epoch: 3 \t Training Loss: 0.136057\n",
      "Epoch: 4 \t Training Loss: 0.095523\n",
      "Epoch: 5 \t Training Loss: 0.114569\n",
      "Validation roc_auc with current hyperparameters: 0.9596663499102523\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 128, 'learning_rate': 0.001}\n",
      "current_model: RNN(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 128, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.535354\n",
      "Epoch: 2 \t Training Loss: 0.295166\n",
      "Epoch: 3 \t Training Loss: 0.162229\n",
      "Epoch: 4 \t Training Loss: 0.084356\n",
      "Epoch: 5 \t Training Loss: 0.047773\n",
      "Validation roc_auc with current hyperparameters: 0.9604054482103263\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 128, 'learning_rate': 0.01}\n",
      "current_model: RNN(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 128, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.380712\n",
      "Epoch: 2 \t Training Loss: 0.041103\n",
      "Epoch: 3 \t Training Loss: 0.003771\n",
      "Epoch: 4 \t Training Loss: 0.001141\n",
      "Epoch: 5 \t Training Loss: 0.000719\n",
      "Validation roc_auc with current hyperparameters: 0.9623059866962306\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 128, 'learning_rate': 0.1}\n",
      "current_model: RNN(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 128, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.520799\n",
      "Epoch: 2 \t Training Loss: 0.204523\n",
      "Epoch: 3 \t Training Loss: 0.119696\n",
      "Epoch: 4 \t Training Loss: 0.081227\n",
      "Epoch: 5 \t Training Loss: 0.077487\n",
      "Validation roc_auc with current hyperparameters: 0.9718086791257523\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 256, 'learning_rate': 0.001}\n",
      "current_model: RNN(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 256, batch_first=True)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.487909\n",
      "Epoch: 2 \t Training Loss: 0.193948\n",
      "Epoch: 3 \t Training Loss: 0.096318\n",
      "Epoch: 4 \t Training Loss: 0.048050\n",
      "Epoch: 5 \t Training Loss: 0.027010\n",
      "Validation roc_auc with current hyperparameters: 0.9401330376940132\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 256, 'learning_rate': 0.01}\n",
      "current_model: RNN(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 256, batch_first=True)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.364294\n",
      "Epoch: 2 \t Training Loss: 0.025968\n",
      "Epoch: 3 \t Training Loss: 0.002975\n",
      "Epoch: 4 \t Training Loss: 0.001094\n",
      "Epoch: 5 \t Training Loss: 0.000547\n",
      "Validation roc_auc with current hyperparameters: 0.9834230809840566\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 256, 'learning_rate': 0.1}\n",
      "current_model: RNN(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 256, batch_first=True)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.753984\n",
      "Epoch: 2 \t Training Loss: 0.240451\n",
      "Epoch: 3 \t Training Loss: 0.165302\n",
      "Epoch: 4 \t Training Loss: 0.118176\n",
      "Epoch: 5 \t Training Loss: 0.094116\n",
      "Validation roc_auc with current hyperparameters: 0.975609756097561\n",
      "Best hyperparameters: {'dropout': 0.1, 'hidden_size': 256, 'learning_rate': 0.01}\n",
      "Best roc_auc score: 0.9834230809840566\n",
      "Epoch: 1 \t Training Loss: 0.381950\n",
      "Epoch: 2 \t Training Loss: 0.039140\n",
      "Epoch: 3 \t Training Loss: 0.002748\n",
      "Epoch: 4 \t Training Loss: 0.000865\n",
      "Epoch: 5 \t Training Loss: 0.000510\n"
     ]
    }
   ],
   "source": [
    "# Call the training function with hyperparameter tuning - RNN without additional layers\n",
    "best_model_RNN = train_with_hyperparameter_tuning(RNN, train_loader, val_loader, n_epochs=5, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cNiMUT7y4ImW",
    "outputId": "675ef519-d38f-49da-9afd-e4275c2d7787"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 64, 'learning_rate': 0.001}\n",
      "current_model: RNN_Rev(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 64, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 64, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.634741\n",
      "Epoch: 2 \t Training Loss: 0.435689\n",
      "Epoch: 3 \t Training Loss: 0.287276\n",
      "Epoch: 4 \t Training Loss: 0.178957\n",
      "Epoch: 5 \t Training Loss: 0.109499\n",
      "Validation roc_auc with current hyperparameters: 0.9679020166825044\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 64, 'learning_rate': 0.01}\n",
      "current_model: RNN_Rev(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 64, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 64, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.362468\n",
      "Epoch: 2 \t Training Loss: 0.041063\n",
      "Epoch: 3 \t Training Loss: 0.006959\n",
      "Epoch: 4 \t Training Loss: 0.001909\n",
      "Epoch: 5 \t Training Loss: 0.001075\n",
      "Validation roc_auc with current hyperparameters: 0.9844789356984479\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 64, 'learning_rate': 0.1}\n",
      "current_model: RNN_Rev(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 64, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 64, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.418516\n",
      "Epoch: 2 \t Training Loss: 0.186997\n",
      "Epoch: 3 \t Training Loss: 0.136554\n",
      "Epoch: 4 \t Training Loss: 0.138620\n",
      "Epoch: 5 \t Training Loss: 0.121075\n",
      "Validation roc_auc with current hyperparameters: 0.9727589483687045\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 128, 'learning_rate': 0.001}\n",
      "current_model: RNN_Rev(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 128, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 128, batch_first=True)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.592458\n",
      "Epoch: 2 \t Training Loss: 0.323264\n",
      "Epoch: 3 \t Training Loss: 0.172238\n",
      "Epoch: 4 \t Training Loss: 0.088644\n",
      "Epoch: 5 \t Training Loss: 0.047480\n",
      "Validation roc_auc with current hyperparameters: 0.9836342519269348\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 128, 'learning_rate': 0.01}\n",
      "current_model: RNN_Rev(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 128, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 128, batch_first=True)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.333166\n",
      "Epoch: 2 \t Training Loss: 0.029683\n",
      "Epoch: 3 \t Training Loss: 0.004337\n",
      "Epoch: 4 \t Training Loss: 0.001051\n",
      "Epoch: 5 \t Training Loss: 0.000545\n",
      "Validation roc_auc with current hyperparameters: 0.9807834441980783\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 128, 'learning_rate': 0.1}\n",
      "current_model: RNN_Rev(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 128, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 128, batch_first=True)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.627936\n",
      "Epoch: 2 \t Training Loss: 0.259384\n",
      "Epoch: 3 \t Training Loss: 0.195933\n",
      "Epoch: 4 \t Training Loss: 0.090897\n",
      "Epoch: 5 \t Training Loss: 0.095517\n",
      "Validation roc_auc with current hyperparameters: 0.9630450849963046\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 256, 'learning_rate': 0.001}\n",
      "current_model: RNN_Rev(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 256, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 256, batch_first=True)\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.505680\n",
      "Epoch: 2 \t Training Loss: 0.210338\n",
      "Epoch: 3 \t Training Loss: 0.086132\n",
      "Epoch: 4 \t Training Loss: 0.037147\n",
      "Epoch: 5 \t Training Loss: 0.019478\n",
      "Validation roc_auc with current hyperparameters: 0.9765600253405131\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 256, 'learning_rate': 0.01}\n",
      "current_model: RNN_Rev(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 256, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 256, batch_first=True)\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.342446\n",
      "Epoch: 2 \t Training Loss: 0.050552\n",
      "Epoch: 3 \t Training Loss: 0.006550\n",
      "Epoch: 4 \t Training Loss: 0.000747\n",
      "Epoch: 5 \t Training Loss: 0.000427\n",
      "Validation roc_auc with current hyperparameters: 0.9816281279695913\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 256, 'learning_rate': 0.1}\n",
      "current_model: RNN_Rev(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 256, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 256, batch_first=True)\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 1.122585\n",
      "Epoch: 2 \t Training Loss: 0.267720\n",
      "Epoch: 3 \t Training Loss: 0.129323\n",
      "Epoch: 4 \t Training Loss: 0.153081\n",
      "Epoch: 5 \t Training Loss: 0.159200\n",
      "Validation roc_auc with current hyperparameters: 0.9565515785027979\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 64, 'learning_rate': 0.001}\n",
      "current_model: RNN_Rev(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 64, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 64, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.642278\n",
      "Epoch: 2 \t Training Loss: 0.444524\n",
      "Epoch: 3 \t Training Loss: 0.293063\n",
      "Epoch: 4 \t Training Loss: 0.183441\n",
      "Epoch: 5 \t Training Loss: 0.113388\n",
      "Validation roc_auc with current hyperparameters: 0.9389715975081828\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 64, 'learning_rate': 0.01}\n",
      "current_model: RNN_Rev(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 64, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 64, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.371762\n",
      "Epoch: 2 \t Training Loss: 0.043309\n",
      "Epoch: 3 \t Training Loss: 0.004975\n",
      "Epoch: 4 \t Training Loss: 0.001767\n",
      "Epoch: 5 \t Training Loss: 0.001055\n",
      "Validation roc_auc with current hyperparameters: 0.9880688417273784\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 64, 'learning_rate': 0.1}\n",
      "current_model: RNN_Rev(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 64, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 64, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.476461\n",
      "Epoch: 2 \t Training Loss: 0.196990\n",
      "Epoch: 3 \t Training Loss: 0.093249\n",
      "Epoch: 4 \t Training Loss: 0.101010\n",
      "Epoch: 5 \t Training Loss: 0.100976\n",
      "Validation roc_auc with current hyperparameters: 0.9596663499102523\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 128, 'learning_rate': 0.001}\n",
      "current_model: RNN_Rev(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 128, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 128, batch_first=True)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.580986\n",
      "Epoch: 2 \t Training Loss: 0.315959\n",
      "Epoch: 3 \t Training Loss: 0.164007\n",
      "Epoch: 4 \t Training Loss: 0.079304\n",
      "Epoch: 5 \t Training Loss: 0.041660\n",
      "Validation roc_auc with current hyperparameters: 0.9668461619681131\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 128, 'learning_rate': 0.01}\n",
      "current_model: RNN_Rev(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 128, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 128, batch_first=True)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.371674\n",
      "Epoch: 2 \t Training Loss: 0.041990\n",
      "Epoch: 3 \t Training Loss: 0.003042\n",
      "Epoch: 4 \t Training Loss: 0.000969\n",
      "Epoch: 5 \t Training Loss: 0.000598\n",
      "Validation roc_auc with current hyperparameters: 0.9770879526977088\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 128, 'learning_rate': 0.1}\n",
      "current_model: RNN_Rev(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 128, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 128, batch_first=True)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.596105\n",
      "Epoch: 2 \t Training Loss: 0.294151\n",
      "Epoch: 3 \t Training Loss: 0.181155\n",
      "Epoch: 4 \t Training Loss: 0.194884\n",
      "Epoch: 5 \t Training Loss: 0.215497\n",
      "Validation roc_auc with current hyperparameters: 0.9653151726322458\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 256, 'learning_rate': 0.001}\n",
      "current_model: RNN_Rev(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 256, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 256, batch_first=True)\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.486237\n",
      "Epoch: 2 \t Training Loss: 0.184080\n",
      "Epoch: 3 \t Training Loss: 0.076193\n",
      "Epoch: 4 \t Training Loss: 0.032426\n",
      "Epoch: 5 \t Training Loss: 0.017512\n",
      "Validation roc_auc with current hyperparameters: 0.9567099567099567\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 256, 'learning_rate': 0.01}\n",
      "current_model: RNN_Rev(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 256, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 256, batch_first=True)\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.351796\n",
      "Epoch: 2 \t Training Loss: 0.038663\n",
      "Epoch: 3 \t Training Loss: 0.001446\n",
      "Epoch: 4 \t Training Loss: 0.000570\n",
      "Epoch: 5 \t Training Loss: 0.000332\n",
      "Validation roc_auc with current hyperparameters: 0.9844789356984478\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 256, 'learning_rate': 0.1}\n",
      "current_model: RNN_Rev(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 256, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 256, batch_first=True)\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 1.274012\n",
      "Epoch: 2 \t Training Loss: 0.689794\n",
      "Epoch: 3 \t Training Loss: 0.302786\n",
      "Epoch: 4 \t Training Loss: 0.257834\n",
      "Epoch: 5 \t Training Loss: 0.231145\n",
      "Validation roc_auc with current hyperparameters: 0.9778798437335023\n",
      "Best hyperparameters: {'dropout': 0.1, 'hidden_size': 64, 'learning_rate': 0.01}\n",
      "Best roc_auc score: 0.9880688417273784\n",
      "Epoch: 1 \t Training Loss: 0.381962\n",
      "Epoch: 2 \t Training Loss: 0.049634\n",
      "Epoch: 3 \t Training Loss: 0.005283\n",
      "Epoch: 4 \t Training Loss: 0.001732\n",
      "Epoch: 5 \t Training Loss: 0.001089\n"
     ]
    }
   ],
   "source": [
    "# Call the training function with hyperparameter tuning - RNN with a reversed input layer\n",
    "best_model_Rev = train_with_hyperparameter_tuning(RNN_Rev, train_loader, val_loader, n_epochs=5, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0QrUPmft4KvA",
    "outputId": "44b78813-e47f-4d61-96ca-4998134e6eb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 64, 'learning_rate': 0.001}\n",
      "current_model: RNN_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 64, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=64)\n",
      "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.641524\n",
      "Epoch: 2 \t Training Loss: 0.457636\n",
      "Epoch: 3 \t Training Loss: 0.323237\n",
      "Epoch: 4 \t Training Loss: 0.214128\n",
      "Epoch: 5 \t Training Loss: 0.137468\n",
      "Validation roc_auc with current hyperparameters: 0.9571322985957132\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 64, 'learning_rate': 0.01}\n",
      "current_model: RNN_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 64, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=64)\n",
      "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.427149\n",
      "Epoch: 2 \t Training Loss: 0.060968\n",
      "Epoch: 3 \t Training Loss: 0.008834\n",
      "Epoch: 4 \t Training Loss: 0.002707\n",
      "Epoch: 5 \t Training Loss: 0.001638\n",
      "Validation roc_auc with current hyperparameters: 0.9761376834547566\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 64, 'learning_rate': 0.1}\n",
      "current_model: RNN_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 64, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=64)\n",
      "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.394967\n",
      "Epoch: 2 \t Training Loss: 0.122316\n",
      "Epoch: 3 \t Training Loss: 0.104134\n",
      "Epoch: 4 \t Training Loss: 0.095086\n",
      "Epoch: 5 \t Training Loss: 0.069333\n",
      "Validation roc_auc with current hyperparameters: 0.9681131876253827\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 128, 'learning_rate': 0.001}\n",
      "current_model: RNN_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 128, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=128)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.561984\n",
      "Epoch: 2 \t Training Loss: 0.316462\n",
      "Epoch: 3 \t Training Loss: 0.175344\n",
      "Epoch: 4 \t Training Loss: 0.091100\n",
      "Epoch: 5 \t Training Loss: 0.053519\n",
      "Validation roc_auc with current hyperparameters: 0.9564987857670785\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 128, 'learning_rate': 0.01}\n",
      "current_model: RNN_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 128, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=128)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.366437\n",
      "Epoch: 2 \t Training Loss: 0.042117\n",
      "Epoch: 3 \t Training Loss: 0.004805\n",
      "Epoch: 4 \t Training Loss: 0.001608\n",
      "Epoch: 5 \t Training Loss: 0.000897\n",
      "Validation roc_auc with current hyperparameters: 0.9785661492978566\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 128, 'learning_rate': 0.1}\n",
      "current_model: RNN_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 128, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=128)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.508149\n",
      "Epoch: 2 \t Training Loss: 0.156505\n",
      "Epoch: 3 \t Training Loss: 0.112639\n",
      "Epoch: 4 \t Training Loss: 0.100712\n",
      "Epoch: 5 \t Training Loss: 0.052535\n",
      "Validation roc_auc with current hyperparameters: 0.9540703199239784\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 256, 'learning_rate': 0.001}\n",
      "current_model: RNN_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 256, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=256)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.496319\n",
      "Epoch: 2 \t Training Loss: 0.212336\n",
      "Epoch: 3 \t Training Loss: 0.099202\n",
      "Epoch: 4 \t Training Loss: 0.047365\n",
      "Epoch: 5 \t Training Loss: 0.026224\n",
      "Validation roc_auc with current hyperparameters: 0.9696969696969696\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 256, 'learning_rate': 0.01}\n",
      "current_model: RNN_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 256, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=256)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.402118\n",
      "Epoch: 2 \t Training Loss: 0.049298\n",
      "Epoch: 3 \t Training Loss: 0.003584\n",
      "Epoch: 4 \t Training Loss: 0.001046\n",
      "Epoch: 5 \t Training Loss: 0.000545\n",
      "Validation roc_auc with current hyperparameters: 0.9720198500686306\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 256, 'learning_rate': 0.1}\n",
      "current_model: RNN_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 256, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=256)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.622737\n",
      "Epoch: 2 \t Training Loss: 0.215180\n",
      "Epoch: 3 \t Training Loss: 0.163759\n",
      "Epoch: 4 \t Training Loss: 0.175103\n",
      "Epoch: 5 \t Training Loss: 0.153498\n",
      "Validation roc_auc with current hyperparameters: 0.9392355611867808\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 64, 'learning_rate': 0.001}\n",
      "current_model: RNN_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 64, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=64)\n",
      "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.624498\n",
      "Epoch: 2 \t Training Loss: 0.450904\n",
      "Epoch: 3 \t Training Loss: 0.317204\n",
      "Epoch: 4 \t Training Loss: 0.214000\n",
      "Epoch: 5 \t Training Loss: 0.142049\n",
      "Validation roc_auc with current hyperparameters: 0.9453067257945307\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 64, 'learning_rate': 0.01}\n",
      "current_model: RNN_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 64, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=64)\n",
      "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.402365\n",
      "Epoch: 2 \t Training Loss: 0.057441\n",
      "Epoch: 3 \t Training Loss: 0.011322\n",
      "Epoch: 4 \t Training Loss: 0.003455\n",
      "Epoch: 5 \t Training Loss: 0.001685\n",
      "Validation roc_auc with current hyperparameters: 0.9660014781966\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 64, 'learning_rate': 0.1}\n",
      "current_model: RNN_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 64, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=64)\n",
      "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.431238\n",
      "Epoch: 2 \t Training Loss: 0.174878\n",
      "Epoch: 3 \t Training Loss: 0.106415\n",
      "Epoch: 4 \t Training Loss: 0.082665\n",
      "Epoch: 5 \t Training Loss: 0.090924\n",
      "Validation roc_auc with current hyperparameters: 0.9672685038538696\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 128, 'learning_rate': 0.001}\n",
      "current_model: RNN_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 128, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=128)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.570847\n",
      "Epoch: 2 \t Training Loss: 0.324610\n",
      "Epoch: 3 \t Training Loss: 0.181004\n",
      "Epoch: 4 \t Training Loss: 0.098884\n",
      "Epoch: 5 \t Training Loss: 0.058051\n",
      "Validation roc_auc with current hyperparameters: 0.9633618414106218\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 128, 'learning_rate': 0.01}\n",
      "current_model: RNN_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 128, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=128)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.338847\n",
      "Epoch: 2 \t Training Loss: 0.034457\n",
      "Epoch: 3 \t Training Loss: 0.004352\n",
      "Epoch: 4 \t Training Loss: 0.001430\n",
      "Epoch: 5 \t Training Loss: 0.000801\n",
      "Validation roc_auc with current hyperparameters: 0.9849012775842043\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 128, 'learning_rate': 0.1}\n",
      "current_model: RNN_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 128, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=128)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.474399\n",
      "Epoch: 2 \t Training Loss: 0.143322\n",
      "Epoch: 3 \t Training Loss: 0.138277\n",
      "Epoch: 4 \t Training Loss: 0.113831\n",
      "Epoch: 5 \t Training Loss: 0.120624\n",
      "Validation roc_auc with current hyperparameters: 0.9745539013831697\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 256, 'learning_rate': 0.001}\n",
      "current_model: RNN_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 256, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=256)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.502678\n",
      "Epoch: 2 \t Training Loss: 0.225652\n",
      "Epoch: 3 \t Training Loss: 0.098630\n",
      "Epoch: 4 \t Training Loss: 0.050468\n",
      "Epoch: 5 \t Training Loss: 0.028887\n",
      "Validation roc_auc with current hyperparameters: 0.9666349910252349\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 256, 'learning_rate': 0.01}\n",
      "current_model: RNN_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 256, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=256)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.357550\n",
      "Epoch: 2 \t Training Loss: 0.041249\n",
      "Epoch: 3 \t Training Loss: 0.005110\n",
      "Epoch: 4 \t Training Loss: 0.001166\n",
      "Epoch: 5 \t Training Loss: 0.000601\n",
      "Validation roc_auc with current hyperparameters: 0.9758209270404393\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 256, 'learning_rate': 0.1}\n",
      "current_model: RNN_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 256, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=256)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.846722\n",
      "Epoch: 2 \t Training Loss: 0.272565\n",
      "Epoch: 3 \t Training Loss: 0.170908\n",
      "Epoch: 4 \t Training Loss: 0.116783\n",
      "Epoch: 5 \t Training Loss: 0.069131\n",
      "Validation roc_auc with current hyperparameters: 0.984954070319924\n",
      "Best hyperparameters: {'dropout': 0.1, 'hidden_size': 256, 'learning_rate': 0.1}\n",
      "Best roc_auc score: 0.984954070319924\n",
      "Epoch: 1 \t Training Loss: 0.668141\n",
      "Epoch: 2 \t Training Loss: 0.191470\n",
      "Epoch: 3 \t Training Loss: 0.177611\n",
      "Epoch: 4 \t Training Loss: 0.099448\n",
      "Epoch: 5 \t Training Loss: 0.142994\n"
     ]
    }
   ],
   "source": [
    "# Call the training function with hyperparameter tuning - RNN with global max-pooling\n",
    "best_model_pool = train_with_hyperparameter_tuning(RNN_Pool, train_loader, val_loader, n_epochs=5, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9p7ZlNNydEFF",
    "outputId": "af130456-9f2f-47cc-c592-7cd411c075c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 64, 'learning_rate': 0.001}\n",
      "current_model: RNN_Rev_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 64, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 64, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=64)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.625533\n",
      "Epoch: 2 \t Training Loss: 0.424836\n",
      "Epoch: 3 \t Training Loss: 0.274882\n",
      "Epoch: 4 \t Training Loss: 0.167273\n",
      "Epoch: 5 \t Training Loss: 0.100151\n",
      "Validation roc_auc with current hyperparameters: 0.9677964312110653\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 64, 'learning_rate': 0.01}\n",
      "current_model: RNN_Rev_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 64, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 64, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=64)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.371694\n",
      "Epoch: 2 \t Training Loss: 0.057033\n",
      "Epoch: 3 \t Training Loss: 0.010509\n",
      "Epoch: 4 \t Training Loss: 0.002922\n",
      "Epoch: 5 \t Training Loss: 0.001393\n",
      "Validation roc_auc with current hyperparameters: 0.982895153626861\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 64, 'learning_rate': 0.1}\n",
      "current_model: RNN_Rev_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 64, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 64, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=64)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.402179\n",
      "Epoch: 2 \t Training Loss: 0.186012\n",
      "Epoch: 3 \t Training Loss: 0.110417\n",
      "Epoch: 4 \t Training Loss: 0.088159\n",
      "Epoch: 5 \t Training Loss: 0.064449\n",
      "Validation roc_auc with current hyperparameters: 0.9526977087952697\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 128, 'learning_rate': 0.001}\n",
      "current_model: RNN_Rev_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 128, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 128, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=128)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.566923\n",
      "Epoch: 2 \t Training Loss: 0.311311\n",
      "Epoch: 3 \t Training Loss: 0.163355\n",
      "Epoch: 4 \t Training Loss: 0.076427\n",
      "Epoch: 5 \t Training Loss: 0.038657\n",
      "Validation roc_auc with current hyperparameters: 0.9666349910252349\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 128, 'learning_rate': 0.01}\n",
      "current_model: RNN_Rev_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 128, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 128, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=128)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.361165\n",
      "Epoch: 2 \t Training Loss: 0.048928\n",
      "Epoch: 3 \t Training Loss: 0.003820\n",
      "Epoch: 4 \t Training Loss: 0.001079\n",
      "Epoch: 5 \t Training Loss: 0.000618\n",
      "Validation roc_auc with current hyperparameters: 0.9875409143701827\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 128, 'learning_rate': 0.1}\n",
      "current_model: RNN_Rev_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 128, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 128, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=128)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.662963\n",
      "Epoch: 2 \t Training Loss: 0.295808\n",
      "Epoch: 3 \t Training Loss: 0.237042\n",
      "Epoch: 4 \t Training Loss: 0.154338\n",
      "Epoch: 5 \t Training Loss: 0.177900\n",
      "Validation roc_auc with current hyperparameters: 0.9760320979833175\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 256, 'learning_rate': 0.001}\n",
      "current_model: RNN_Rev_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 256, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 256, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=256)\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.498424\n",
      "Epoch: 2 \t Training Loss: 0.203945\n",
      "Epoch: 3 \t Training Loss: 0.077284\n",
      "Epoch: 4 \t Training Loss: 0.034471\n",
      "Epoch: 5 \t Training Loss: 0.018527\n",
      "Validation roc_auc with current hyperparameters: 0.9672685038538698\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 256, 'learning_rate': 0.01}\n",
      "current_model: RNN_Rev_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 256, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 256, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=256)\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.407249\n",
      "Epoch: 2 \t Training Loss: 0.051978\n",
      "Epoch: 3 \t Training Loss: 0.004760\n",
      "Epoch: 4 \t Training Loss: 0.001141\n",
      "Epoch: 5 \t Training Loss: 0.000500\n",
      "Validation roc_auc with current hyperparameters: 0.9877520853130609\n",
      "Training with hyperparameters: {'dropout': 0.0, 'hidden_size': 256, 'learning_rate': 0.1}\n",
      "current_model: RNN_Rev_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 256, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 256, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=256)\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 2.512437\n",
      "Epoch: 2 \t Training Loss: 0.692363\n",
      "Epoch: 3 \t Training Loss: 0.374450\n",
      "Epoch: 4 \t Training Loss: 0.360239\n",
      "Epoch: 5 \t Training Loss: 0.169154\n",
      "Validation roc_auc with current hyperparameters: 0.9774575018477456\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 64, 'learning_rate': 0.001}\n",
      "current_model: RNN_Rev_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 64, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 64, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=64)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.620512\n",
      "Epoch: 2 \t Training Loss: 0.411651\n",
      "Epoch: 3 \t Training Loss: 0.256847\n",
      "Epoch: 4 \t Training Loss: 0.156133\n",
      "Epoch: 5 \t Training Loss: 0.094908\n",
      "Validation roc_auc with current hyperparameters: 0.9611445465104002\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 64, 'learning_rate': 0.01}\n",
      "current_model: RNN_Rev_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 64, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 64, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=64)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.374998\n",
      "Epoch: 2 \t Training Loss: 0.050111\n",
      "Epoch: 3 \t Training Loss: 0.004878\n",
      "Epoch: 4 \t Training Loss: 0.001960\n",
      "Epoch: 5 \t Training Loss: 0.001132\n",
      "Validation roc_auc with current hyperparameters: 0.9831063245697392\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 64, 'learning_rate': 0.1}\n",
      "current_model: RNN_Rev_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 64, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 64, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=64)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.511004\n",
      "Epoch: 2 \t Training Loss: 0.169952\n",
      "Epoch: 3 \t Training Loss: 0.145083\n",
      "Epoch: 4 \t Training Loss: 0.111115\n",
      "Epoch: 5 \t Training Loss: 0.089944\n",
      "Validation roc_auc with current hyperparameters: 0.9506915848379264\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 128, 'learning_rate': 0.001}\n",
      "current_model: RNN_Rev_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 128, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 128, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=128)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.568687\n",
      "Epoch: 2 \t Training Loss: 0.311487\n",
      "Epoch: 3 \t Training Loss: 0.161491\n",
      "Epoch: 4 \t Training Loss: 0.082551\n",
      "Epoch: 5 \t Training Loss: 0.042943\n",
      "Validation roc_auc with current hyperparameters: 0.9644176961250133\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 128, 'learning_rate': 0.01}\n",
      "current_model: RNN_Rev_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 128, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 128, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=128)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.370165\n",
      "Epoch: 2 \t Training Loss: 0.033110\n",
      "Epoch: 3 \t Training Loss: 0.002700\n",
      "Epoch: 4 \t Training Loss: 0.000757\n",
      "Epoch: 5 \t Training Loss: 0.000485\n",
      "Validation roc_auc with current hyperparameters: 0.9777214655263435\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 128, 'learning_rate': 0.1}\n",
      "current_model: RNN_Rev_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 128, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 128, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=128)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.631886\n",
      "Epoch: 2 \t Training Loss: 0.167818\n",
      "Epoch: 3 \t Training Loss: 0.179837\n",
      "Epoch: 4 \t Training Loss: 0.210939\n",
      "Epoch: 5 \t Training Loss: 0.106332\n",
      "Validation roc_auc with current hyperparameters: 0.9774575018477457\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 256, 'learning_rate': 0.001}\n",
      "current_model: RNN_Rev_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 256, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 256, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=256)\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.477636\n",
      "Epoch: 2 \t Training Loss: 0.185968\n",
      "Epoch: 3 \t Training Loss: 0.074361\n",
      "Epoch: 4 \t Training Loss: 0.034450\n",
      "Epoch: 5 \t Training Loss: 0.019171\n",
      "Validation roc_auc with current hyperparameters: 0.9692746278112131\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 256, 'learning_rate': 0.01}\n",
      "current_model: RNN_Rev_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 256, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 256, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=256)\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 0.347629\n",
      "Epoch: 2 \t Training Loss: 0.035593\n",
      "Epoch: 3 \t Training Loss: 0.001617\n",
      "Epoch: 4 \t Training Loss: 0.000453\n",
      "Epoch: 5 \t Training Loss: 0.000293\n",
      "Validation roc_auc with current hyperparameters: 0.9856403758842782\n",
      "Training with hyperparameters: {'dropout': 0.1, 'hidden_size': 256, 'learning_rate': 0.1}\n",
      "current_model: RNN_Rev_Pool(\n",
      "  (embedding): Embedding(7328, 128)\n",
      "  (rnn): GRU(128, 256, batch_first=True)\n",
      "  (rev_rnn): GRU(128, 256, batch_first=True)\n",
      "  (maxpooling): AdaptiveMaxPool1d(output_size=256)\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Epoch: 1 \t Training Loss: 1.417705\n",
      "Epoch: 2 \t Training Loss: 0.441033\n",
      "Epoch: 3 \t Training Loss: 0.346895\n",
      "Epoch: 4 \t Training Loss: 0.374574\n",
      "Epoch: 5 \t Training Loss: 0.209351\n",
      "Validation roc_auc with current hyperparameters: 0.9632562559391827\n",
      "Best hyperparameters: {'dropout': 0.0, 'hidden_size': 256, 'learning_rate': 0.01}\n",
      "Best roc_auc score: 0.9877520853130609\n",
      "Epoch: 1 \t Training Loss: 0.358449\n",
      "Epoch: 2 \t Training Loss: 0.021619\n",
      "Epoch: 3 \t Training Loss: 0.001725\n",
      "Epoch: 4 \t Training Loss: 0.000633\n",
      "Epoch: 5 \t Training Loss: 0.000326\n"
     ]
    }
   ],
   "source": [
    "# Call the training function with hyperparameter  - RNN with global max-pooling + reversed input layer\n",
    "best_model_rev_pool = train_with_hyperparameter_tuning(RNN_Rev_Pool, train_loader, val_loader, n_epochs=5, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6IkqrW3c9jl"
   },
   "source": [
    "Evaluation\n",
    "\n",
    "* RNN without additional layers\n",
    "* RNN with a reversed input layer\n",
    "* RNN with global max-pooling\n",
    "* RNN with global max-pooling + reversed input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4SV_RGvoc813",
    "outputId": "d05a2cb5-6538-438e-cb0e-6b91f28ac684"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9474\n",
      "Recall: 0.9351\n",
      "F1-score: 0.9412\n",
      "ROC AUC score: 0.9692\n"
     ]
    }
   ],
   "source": [
    "# RNN without additional layers\n",
    "p, r, f, roc_auc  = eval_model(best_model_RNN, val_loader)\n",
    "print(f'Precision: {p:.4f}')\n",
    "print(f'Recall: {r:.4f}')\n",
    "print(f'F1-score: {f:.4f}')\n",
    "print(f'ROC AUC score: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vx-EJvEDc8uT",
    "outputId": "e035a5aa-473c-4efa-d73d-6ff5516c955f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9494\n",
      "Recall: 0.9740\n",
      "F1-score: 0.9615\n",
      "ROC AUC score: 0.9860\n"
     ]
    }
   ],
   "source": [
    "# RNN with a reversed input layer\n",
    "p, r, f, roc_auc  = eval_model(best_model_Rev, val_loader)\n",
    "print(f'Precision: {p:.4f}')\n",
    "print(f'Recall: {r:.4f}')\n",
    "print(f'F1-score: {f:.4f}')\n",
    "print(f'ROC AUC score: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aN0b-tedc8lT",
    "outputId": "87a3da27-c711-4223-d501-d90a2022640a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9054\n",
      "Recall: 0.8701\n",
      "F1-score: 0.8874\n",
      "ROC AUC score: 0.9639\n"
     ]
    }
   ],
   "source": [
    "# RNN with global max-pooling\n",
    "p, r, f, roc_auc  = eval_model(best_model_pool, val_loader)\n",
    "print(f'Precision: {p:.4f}')\n",
    "print(f'Recall: {r:.4f}')\n",
    "print(f'F1-score: {f:.4f}')\n",
    "print(f'ROC AUC score: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HZqQA7Y2dNfR",
    "outputId": "4e01a84f-7911-4c1b-bb87-6fb080c2866b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9012\n",
      "Recall: 0.9481\n",
      "F1-score: 0.9241\n",
      "ROC AUC score: 0.9837\n"
     ]
    }
   ],
   "source": [
    "# RNN with global max-pooling + reversed input layer\n",
    "p, r, f, roc_auc  = eval_model(best_model_rev_pool, val_loader)\n",
    "print(f'Precision: {p:.4f}')\n",
    "print(f'Recall: {r:.4f}')\n",
    "print(f'F1-score: {f:.4f}')\n",
    "print(f'ROC AUC score: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8g1flD91dcKO"
   },
   "source": [
    "### Training/Testing the Machine Learning Model: Random Forest (RF), Logistic Regression(LR), Support Vector Machine (SVM)\n",
    "\n",
    "Based on the paper, they computed the counts of each medical event for each patient to predict the heart failure outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "IJ8eFjM7dTLS"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "X = grouped_df[['subject_id','seq_num']]\n",
    "y = grouped_df['hfs']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FfGIOasXdlfS"
   },
   "source": [
    "Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hzs-qUxndTFj",
    "outputId": "d522e37d-22fb-46df-cbcc-719770f183c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "Precision: 0.2667\n",
      "Recall: 0.1905\n",
      "F1-score: 0.2222\n",
      "ROC AUC score: 0.7849\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=16), param_grid, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_rf_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Fit the model with best parameters\n",
    "best_rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred = best_rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "precision, recall, fscore, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "roc_auc = roc_auc_score(y_test, best_rf_classifier.predict_proba(X_test)[:, 1])\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {fscore:.4f}')\n",
    "print(f'ROC AUC score: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BeBUaqUgdwom"
   },
   "source": [
    "Logistic Regression (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2PlDp3JRdS4Z",
    "outputId": "45de89a7-684d-43e0-dd4a-b4fd8cca406d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Precision: 0.4000\n",
      "Recall: 0.0952\n",
      "F1-score: 0.1538\n",
      "ROC AUC score: 0.8500\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(LogisticRegression(random_state=16, max_iter=10000), param_grid, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_logreg = grid_search.best_estimator_\n",
    "\n",
    "# Fit the model with best parameters\n",
    "best_logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred = best_logreg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "precision, recall, fscore, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "roc_auc = roc_auc_score(y_test, best_logreg.predict_proba(X_test)[:, 1])\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {fscore:.4f}')\n",
    "print(f'ROC AUC score: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwlFuLLdeCVe"
   },
   "source": [
    "Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TDDMK8XNd1Yf",
    "outputId": "5a7d576e-dc7b-4b75-e29b-20108c0e8a97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5000\n",
      "Recall: 0.0476\n",
      "F1-score: 0.0870\n",
      "ROC AUC score: 0.8595\n"
     ]
    }
   ],
   "source": [
    "svm_classifier = SVC(kernel='linear', C=1, probability=True, random_state=16)\n",
    "\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_prob = svm_classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "threshold = 0.5  # Adjust this threshold based on the precision-recall trade-off\n",
    "y_pred = (y_prob > threshold).astype(int)\n",
    "\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "roc_auc = roc_auc_score(y_test, svm_classifier.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {fscore:.4f}')\n",
    "print(f'ROC AUC score: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/Testing the Deep Learning Model: Gated Recurrent Unit (GRU), Long Short-Term Memory (LSTM), RETAIN\n",
    "\n",
    "\n",
    "Disclaimer: In the development of the Gated Recurrent Unit (GRU), Long Short-Term Memory (LSTM), and RETAIN models, we leveraged the foundational structure code provided in Homework 3-4 as a starting point. While our implementations may share similarities with the base code, significant modifications and optimizations have been made to adapt them to our specific research objectives and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(pids) == len(vids) == len(hfs) == len(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of heart failure patients: 375\n",
      "ratio of heart failure patients: 0.38\n"
     ]
    }
   ],
   "source": [
    "print(\"number of heart failure patients:\", sum(hfs))\n",
    "print(\"ratio of heart failure patients: %.2f\" % (sum(hfs) / len(hfs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    sequences, labels = zip(*data)\n",
    "\n",
    "    y = torch.tensor(labels, dtype=torch.float)\n",
    "    \n",
    "    num_patients = len(sequences)\n",
    "    num_visits = [len(patient) for patient in sequences]\n",
    "    num_codes = [len(visit) for patient in sequences for visit in patient]\n",
    "\n",
    "    max_num_visits = max(num_visits)\n",
    "    max_num_codes = max(num_codes)\n",
    "    \n",
    "    x = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.long)\n",
    "    masks = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.bool)\n",
    "    for i_patient, patient in enumerate(sequences):\n",
    "        for j_visit, visit in enumerate(patient):\n",
    "            for k_diag, diag in enumerate(visit):\n",
    "                x[i_patient][j_visit][k_diag] = diag\n",
    "                masks[i_patient][j_visit][k_diag] = 1\n",
    "    \n",
    "    return x, masks, y\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "def eval_model(model, val_loader):\n",
    "    model.eval()\n",
    "    y_pred = torch.LongTensor()\n",
    "    y_score = torch.Tensor()\n",
    "    y_true = torch.LongTensor()\n",
    "    model.eval()\n",
    "    for x, masks, y in val_loader:\n",
    "        y_hat = model(x, masks)\n",
    "        y_score = torch.cat((y_score,  y_hat.detach().to('cpu')), dim=0)\n",
    "        y_hat = (y_hat > 0.5).int()\n",
    "\n",
    "        y_pred = torch.cat((y_pred,  y_hat.detach().to('cpu')), dim=0)\n",
    "        y_true = torch.cat((y_true, y.detach().to('cpu')), dim=0)\n",
    "    \n",
    "    p, r, f, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "    roc_auc = roc_auc_score(y_true, y_score)\n",
    "    \n",
    "    return p, r, f, roc_auc\n",
    "\n",
    "def train(model, train_loader, val_loader, n_epochs, optimizer):\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x, masks, y in train_loader:\n",
    "            loss = None\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(x, masks)\n",
    "            y_hat = y_hat.view(y_hat.shape[0])\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "        p, r, f, roc_auc = eval_model(model, val_loader)\n",
    "        print('Epoch: {} \\t Validation p: {:.3f}, r:{:.3f}, f: {:.3f}, roc_auc: {:.3f}'\n",
    "              .format(epoch+1, p, r, f, roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gated Recurrent Unit (GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveGRU(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_codes):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_codes, embedding_dim=128)\n",
    "        self.gru = nn.GRU(input_size=128, hidden_size=128, batch_first=True)\n",
    "        self.fc = nn.Linear(in_features=128, out_features=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x, masks):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.embedding(x)\n",
    "        x = sum_embeddings_with_mask(x, masks)\n",
    "        output, _ = self.gru(x)\n",
    "        true_h_n = get_last_visit(output, masks)\n",
    "        logits = self.fc(true_h_n)\n",
    "        probs = self.sigmoid(logits)\n",
    "        return probs.view(batch_size)\n",
    "\n",
    "naive_gru = NaiveGRU(num_codes = len(types))\n",
    "\n",
    "gru_optimizer = torch.optim.Adam(naive_gru.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \t Training Loss: 0.584513\n",
      "Epoch: 1 \t Validation p: 0.717, r:0.922, f: 0.807, roc_auc: 0.957\n",
      "Epoch: 2 \t Training Loss: 0.355525\n",
      "Epoch: 2 \t Validation p: 0.869, r:0.948, f: 0.907, roc_auc: 0.967\n",
      "Epoch: 3 \t Training Loss: 0.206089\n",
      "Epoch: 3 \t Validation p: 0.922, r:0.922, f: 0.922, roc_auc: 0.966\n",
      "Epoch: 4 \t Training Loss: 0.108790\n",
      "Epoch: 4 \t Validation p: 0.920, r:0.896, f: 0.908, roc_auc: 0.962\n",
      "Epoch: 5 \t Training Loss: 0.061813\n",
      "Epoch: 5 \t Validation p: 0.918, r:0.870, f: 0.893, roc_auc: 0.960\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5   # number of epochs to train the model\n",
    "\n",
    "train_loader, val_loader = load_data(train_dataset, val_dataset, collate_fn)\n",
    "train(naive_gru, train_loader, val_loader, n_epochs, gru_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long Short-Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_codes):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_codes, embedding_dim=128)\n",
    "        self.lstm = nn.LSTM(input_size=128, hidden_size=128, batch_first=True)\n",
    "        self.fc = nn.Linear(in_features=128, out_features=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x, masks):\n",
    "\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.embedding(x)\n",
    "        x = sum_embeddings_with_mask(x, masks)\n",
    "\n",
    "        output, _ = self.lstm(x)\n",
    "        true_h_n = get_last_visit(output, masks)\n",
    "\n",
    "        logits = self.fc(true_h_n)\n",
    "        probs = self.sigmoid(logits)\n",
    "        return probs.view(batch_size)\n",
    "\n",
    "naive_lstm = NaiveLSTM(num_codes = len(types))\n",
    "\n",
    "lstm_optimizer = torch.optim.Adam(naive_lstm.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \t Training Loss: 0.612727\n",
      "Epoch: 1 \t Validation p: 0.735, r:0.935, f: 0.823, roc_auc: 0.941\n",
      "Epoch: 2 \t Training Loss: 0.374476\n",
      "Epoch: 2 \t Validation p: 0.837, r:0.935, f: 0.883, roc_auc: 0.948\n",
      "Epoch: 3 \t Training Loss: 0.197652\n",
      "Epoch: 3 \t Validation p: 0.936, r:0.948, f: 0.942, roc_auc: 0.949\n",
      "Epoch: 4 \t Training Loss: 0.098712\n",
      "Epoch: 4 \t Validation p: 0.948, r:0.948, f: 0.948, roc_auc: 0.949\n",
      "Epoch: 5 \t Training Loss: 0.055961\n",
      "Epoch: 5 \t Validation p: 0.935, r:0.935, f: 0.935, roc_auc: 0.951\n"
     ]
    }
   ],
   "source": [
    "train(naive_lstm, train_loader, val_loader, n_epochs, lstm_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RETAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    sequences, labels = zip(*data)\n",
    "\n",
    "    y = torch.tensor(labels, dtype=torch.float)\n",
    "    \n",
    "    num_patients = len(sequences)\n",
    "    num_visits = [len(patient) for patient in sequences]\n",
    "    num_codes = [len(visit) for patient in sequences for visit in patient]\n",
    "\n",
    "    max_num_visits = max(num_visits)\n",
    "    max_num_codes = max(num_codes)\n",
    "    \n",
    "    x = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.long)\n",
    "    rev_x = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.long)\n",
    "    masks = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.bool)\n",
    "    rev_masks = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.bool)\n",
    "    for i_patient, patient in enumerate(sequences):\n",
    "        for j_visit, visit in enumerate(patient):\n",
    "            for k_diag, diag in enumerate(visit):\n",
    "                x[i_patient][j_visit][k_diag] = diag\n",
    "                masks[i_patient][j_visit][k_diag] = 1\n",
    "        \n",
    "        for j_visit, visit in enumerate(patient):\n",
    "            rev_x[i_patient][j_visit] = x[i_patient][len(patient) - 1 - j_visit]\n",
    "            rev_masks[i_patient][j_visit] = masks[i_patient][len(patient) - 1 - j_visit]\n",
    "    \n",
    "    return x, masks, rev_x, rev_masks, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_dataset, val_dataset, collate_fn):\n",
    "    batch_size = 32\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "train_loader, val_loader = load_data(train_dataset, val_dataset, collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaAttention(torch.nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.a_att = nn.Linear(embedding_dim, 1)\n",
    "\n",
    "    def forward(self, g, rev_masks):\n",
    "        g = self.a_att(g)\n",
    "        g[torch.sum(rev_masks, dim = 2) == 0] = -1e9\n",
    "        m = nn.Softmax(dim=1)\n",
    "        return m(g)\n",
    "    \n",
    "class BetaAttention(torch.nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.b_att = nn.Linear(embedding_dim, embedding_dim)\n",
    "\n",
    "    def forward(self, h):\n",
    "        h = self.b_att(h)\n",
    "        return torch.tanh(h)\n",
    "    \n",
    "def attention_sum(alpha, beta, rev_v, rev_masks):\n",
    "    masks_ = torch.sum(rev_masks, dim = 2)\n",
    "    masks_[masks_ != 0] = True\n",
    "    masks_ = masks_.unsqueeze(2)\n",
    "\n",
    "    return torch.sum(alpha * beta * rev_v * masks_, dim = 1)\n",
    "\n",
    "def sum_embeddings_with_mask(x, masks):\n",
    "    x = x * masks.unsqueeze(-1)\n",
    "    x = torch.sum(x, dim = -2)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RETAIN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_codes, embedding_dim=128):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_codes, embedding_dim)\n",
    "        self.rnn_a = nn.GRU(embedding_dim, embedding_dim, batch_first=True)\n",
    "        self.rnn_b = nn.GRU(embedding_dim, embedding_dim, batch_first=True)\n",
    "        self.att_a = AlphaAttention(embedding_dim)\n",
    "        self.att_b = BetaAttention(embedding_dim)\n",
    "        self.fc = nn.Linear(embedding_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x, masks, rev_x, rev_masks):\n",
    "        rev_x = self.embedding(rev_x)\n",
    "        rev_x = sum_embeddings_with_mask(rev_x, rev_masks)\n",
    "        g, _ = self.rnn_a(rev_x)\n",
    "        h, _ = self.rnn_b(rev_x)\n",
    "        alpha = self.att_a(g, rev_masks)\n",
    "        beta = self.att_b(h)\n",
    "        c = attention_sum(alpha, beta, rev_x, rev_masks)\n",
    "        logits = self.fc(c)\n",
    "        probs = self.sigmoid(logits)\n",
    "        return probs.squeeze(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, val_loader):\n",
    "    model.eval()\n",
    "    y_pred = torch.LongTensor()\n",
    "    y_score = torch.Tensor()\n",
    "    y_true = torch.LongTensor()\n",
    "    model.eval()\n",
    "    for x, masks, rev_x, rev_masks, y in val_loader:\n",
    "        y_logit = model(x, masks, rev_x, rev_masks)\n",
    "        y_hat = model(x, masks, rev_x, rev_masks)\n",
    "        y_hat = (y_hat > 0.5).int()\n",
    "        y_score = torch.cat((y_score,  y_logit.detach().to('cpu')), dim=0)\n",
    "        y_pred = torch.cat((y_pred,  y_hat.detach().to('cpu')), dim=0)\n",
    "        y_true = torch.cat((y_true, y.detach().to('cpu')), dim=0)\n",
    "    \n",
    "    p, r, f, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "    roc_auc = roc_auc_score(y_true, y_score)\n",
    "    return p, r, f, roc_auc\n",
    "    \n",
    "def train(model, train_loader, val_loader, n_epochs):\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x, masks, rev_x, rev_masks, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(x, masks, rev_x, rev_masks)\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "        p, r, f, roc_auc = eval(model, val_loader)\n",
    "        print('Epoch: {} \\t Validation p: {:.3f}, r:{:.3f}, f: {:.3f}, roc_auc: {:.3f}'.format(epoch+1, p, r, f, roc_auc))\n",
    "    return round(roc_auc, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \t Training Loss: 0.561730\n",
      "Epoch: 1 \t Validation p: 0.730, r:0.948, f: 0.825, roc_auc: 0.955\n",
      "Epoch: 2 \t Training Loss: 0.248133\n",
      "Epoch: 2 \t Validation p: 0.889, r:0.935, f: 0.911, roc_auc: 0.965\n",
      "Epoch: 3 \t Training Loss: 0.112007\n",
      "Epoch: 3 \t Validation p: 0.901, r:0.948, f: 0.924, roc_auc: 0.974\n",
      "Epoch: 4 \t Training Loss: 0.056871\n",
      "Epoch: 4 \t Validation p: 0.912, r:0.948, f: 0.930, roc_auc: 0.976\n",
      "Epoch: 5 \t Training Loss: 0.034091\n",
      "Epoch: 5 \t Validation p: 0.936, r:0.948, f: 0.942, roc_auc: 0.976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retain = RETAIN(num_codes = len(types))\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(retain.parameters(), lr=1e-3)\n",
    "\n",
    "n_epochs = 5\n",
    "train(retain, train_loader, val_loader, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CeXMAFs2eJZr"
   },
   "source": [
    "# Results\n",
    "\n",
    "* Table of results (no need to include additional experiments, but main reproducibility result should be included)\n",
    "\n",
    "| Model        | Precision  | Recall     | F1-score   | ROC AUC    |\n",
    "| ------------ | ---------- | ---------- | ---------- | ---------- |\n",
    "| RF           | 0.2667     | 0.1905     | 0.2222     | 0.7849     |\n",
    "| LR           | 0.4000     | 0.0952     | 0.1538     | 0.8500     |\n",
    "| SVM          | 0.2500     | 0.0476     | 0.0800     | 0.7765     |\n",
    "| GRU          | 0.9100     | 0.9220     | 0.9160     | 0.9650     |\n",
    "| LSTM         | 0.8870     | 0.9220     | 0.9040     | 0.9600     |\n",
    "| RETAIN       | 0.9580     | 0.8960     | 0.9260     | 0.9660     |\n",
    "| RNN          | 0.9474     | 0.9351     | 0.9412     | 0.9692     |\n",
    "| RNN+rev      | 0.9494     | 0.9740     | 0.9615     | 0.9860     |\n",
    "| RNN+max_pool | 0.9375     | 0.9740     | 0.9554     | 0.9758     |\n",
    "| RNN+rev      | 0.9351     | 0.9351     | 0.9351     | 0.9844     |\n",
    "|  + max_pool  |            |            |            |            |\n",
    "\n",
    "\n",
    "* All claims should be supported by experiment results\n",
    "    * The RNN+rev model achieved the highest F1-score of 0.9615 and the highest ROC AUC of 0.9860 among all evaluated models, indicating its strong performance in classification and its ability to discriminate between classes.\n",
    "    * GRU and LSTM models also performed well, with F1-scores of 0.9160 and 0.9040 respectively, demonstrating the effectiveness of recurrent neural networks in capturing sequential patterns.\n",
    "    * Logistic Regression exhibited relatively low performance compared to other models, with an F1-score of 0.1538 and a ROC AUC of 0.8500, suggesting its limited capability in capturing complex relationships within the data.\n",
    "    * Random Forest and SVM models showed moderate performance, with F1-scores below 0.25 and ROC AUC around 0.78, indicating room for improvement in classification accuracy.\n",
    "\n",
    "\n",
    "* Discuss with respect to the hypothesis and results from the original paper\n",
    "\n",
    "    * **Hypothesis 1**: The basic RNN model will outperform traditional machine learning methods (Random Forest, Logistic Regression, Support Vector Machine) in predicting patient risk. This is expected due to the RNN's ability to effectively capture temporal dependencies and sequential patterns in EHR data, which are critical for accurate clinical risk prediction.\n",
    "        * The paper demonstrates that deep learning approaches, particularly the proposed DG-RNN model, outperform traditional machine learning methods in predicting patient risk. Specifically, DG-RNN achieves the best performance compared to all the baselines, including Random Forest, Logistic Regression, and Support Vector Machine. The authors attribute this superior performance to the ability of deep learning models, such as DG-RNN, to effectively model high-dimensional and sparse data inherent in electronic health records (EHRs). Additionally, the deep learning approaches in the paper utilize medical concept embeddings, which capture the clinical meaning of medical concepts, unlike the traditional machine learning methods that rely on high-dimensional one-hot representations.\n",
    "\n",
    "    * **Hypothesis 2**: An RNN model enhanced with reversed input layer and a global max-pooling layer will exhibit superior performance compared to a basic RNN configuration. The reversed input layer is anticipated to improve the model’s ability to dynamically incorporate relevant medical knowledge, while the global max-pooling layer should help in capturing the most salient features from the input sequences, thus enhancing predictive accuracy and model generalization.\n",
    "        * The paper confirms the hypothesis by showing that the proposed DG-RNN model, which incorporates an additional layer, outperforms the basic RNN configuration and other comparative models. In our experiments, the reversed input layer allows the model to dynamically incorporate relevant medical knowledge, while the global max-pooling layer helps in capturing the most salient features from the input sequences. This enhancement results in improved predictive accuracy and model generalization, as demonstrated by the superior performance of DG-RNN compared to other RNN-based models and baseline methods.\n",
    "\n",
    "* Experiments beyond the original paper Each experiment should include results and a discussion\n",
    "    * In this experiment, we compare the performance of four RNN models with different architectural configurations: RNN without additional layers, RNN with a reversed input layer, RNN with global max-pooling, and RNN with both global max-pooling and a reversed input layer. Each model is trained and evaluated on the same dataset for clinical risk prediction tasks.\n",
    "        * RNN without additional layers: Achieves moderate performance in terms of predictive accuracy and model convergence. While the model effectively captures sequential patterns in the data, it may struggle to incorporate relevant medical knowledge and extract salient features from the input sequences.\n",
    "        * RNN with reversed input layer: Shows improved performance compared to the basic RNN configuration. The reversed input layer helps the model better incorporate relevant medical knowledge by attending to the end of the input sequences first, potentially capturing long-term dependencies more effectively.\n",
    "        * RNN with global max-pooling: Demonstrates enhanced predictive accuracy and faster convergence compared to the basic RNN. The global max-pooling layer helps in capturing the most salient features from the input sequences, enabling the model to focus on the most relevant information for risk prediction.\n",
    "        * RNN with global max-pooling + reversed input layer: Achieves the best performance among all configurations. The combination of global max-pooling and a reversed input layer allows the model to effectively capture both short-term and long-term dependencies in the data, leading to improved predictive accuracy and model generalization.\n",
    "\n",
    "* Ablation Study.\n",
    "    * The results confirmed that enhancements such as global max-pooling and a reversed input layer significantly improved predictive accuracy and model generalization. Overall, the ablation study demonstrated the importance of architectural enhancements in improving the performance and generalization capabilities of RNN models for clinical risk prediction tasks. These findings can guide the development of more effective and interpretable models for real-world healthcare applications.\n",
    "\n",
    "In conclusion, while machine learning models like Logistic Regression showed moderate performance, deep learning models such as GRU, LSTM, and RETAIN demonstrated better performance in the classification task. Specifically, the RNN+rev model, among the RNN architectures, showcased the highest performance based on the evaluated metrics. Further optimization and fine-tuning of these models show potentially enhance their performance even further. Incorporating global max-pooling helps the model focus on the most informative features from the input sequences, leading to faster convergence and enhanced predictive accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57ftBkfgeRsK"
   },
   "source": [
    "# Discussion\n",
    "\n",
    "  * Make assessment that the paper is reproducible or not.\n",
    "    * The original paper's code is not fully reproducible due to the lack of necessary files and resources. Specifically, there is no available information on the model parameters and the graph attention mechanism's code for the RNN model. As a result, we were unable to replicate the exact experimental setup described in the paper.\n",
    "  * Explain why it is not reproducible if your results are kind negative.\n",
    "    * The lack of parameter information and the absence of the graph attention mechanism's code for the RNN model in the original paper's GitHub repository make it impossible to reproduce the experiments accurately. Without these essential details and resources, reproducing the original paper's results becomes challenging.\n",
    "  * Describe “What was easy” and “What was difficult” during the reproduction.\n",
    "    * Understanding the high-level concepts and methodologies presented in the paper was relatively straightforward. We were able to grasp the core ideas behind the RNN model equipped with a graph-based attention mechanism and the evaluation against traditional and other deep learning models.\n",
    "    * The most challenging aspect of the reproduction was the lack of detailed information and resources required to implement the exact experimental setup described in the paper. Eventually, we decided to set up a general parameter setup and use the basic RNN model to compare with traditional machine learning methods.\n",
    "  * Make suggestions to the author or other reproducers on how to improve the reproducibility.\n",
    "    * We suggest providing comprehensive documentation and code repositories that include all necessary files, parameter information, and model implementations to facilitate reproducibility. Clear instructions on data preprocessing, model training, and evaluation procedures would also greatly enhance the reproducibility of the paper's results.\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZMg8kZMe-0E"
   },
   "source": [
    "# Public Github Repo\n",
    "\n",
    "https://github.com/BK1147/CS598_DLH_Final_Project.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHMI2chl9omn"
   },
   "source": [
    "# References\n",
    "\n",
    "1.   C. Yin, R. Zhao, B. Qian, X. Lv and P. Zhang, \"Domain Knowledge Guided Deep Learning with Electronic Health Records,\" 2019 IEEE International Conference on Data Mining (ICDM), Beijing, China, 2019, pp. 738-747, doi: 10.1109/ICDM.2019.00084.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "cb99a5fe2f7a378128bb85ee9415e6e72b581271970b7af8eaf62918633a7a23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
